---
title: "Take-home Exercise 4"
author: "Li Jiayi"
date: "03/06/24"
date-modified: "last-modified"
execute:
  eval: true
  echo: true 
  warning: false
  freeze: true
code-fold: true
code-summary: "Show the code"
date-format: long
---

# Project Component

This project have the following the component:

1.  Uni-Vraiant & Time series Analysis
2.  Multi-Variant Analysis
3.  Geospatial Analysis
4.  Modeling
    -   Panel Regression
    -   Network Analysis
    -   Time Series Clustering

This take home exercise will cover on Multi-Variant Analysis, and Time Series Clustering.

# Data Preparation

Please refer to [this link](https://isss608-24jan-group1.netlify.app/prototype/data_preparation/data_preparation) for the complete data preparation process contributed by all team members. The final dataset within the group.

## Loading R packages

```{r}
#| code-fold: false
pacman::p_load(ggiraph, plotly, tidyverse,
               corrplot, ggstatsplot,
               heatmaply, treemap, dplyr)
```

## **Importing Data**

The code below uses the **`read_csv()`** function from the **readr** package to import **`bmi_data.csv`** and **`country_data.csv`** into the environment.

```{r}
#| code-fold: false
bmi <- read_csv("data/bmi_data.csv")
country <- read_csv("data/country_data.csv")
```

Two datasets are used: **`bmi_data`** contains the target variable, Big Mac Index, and a list of economic indicators from 28 countries and regions for the years 2002 to 2022. This data has already been cleaned and manipulated for analysis. **`country_data`** contains geographical and economic category groups for the 28 countries and regions involved, such as EU, continent, and G20 etc.

::: panel-tabset
## BMI

```{r}
#| code-fold: false
head(bmi)
```

## Region

```{r}
#| code-fold: false
head(country)
```

## Combined

Left join country with bmi data by country name, and take a preview of the data

```{r}
#| code-fold: false
bmi_all <- left_join(bmi, country, by = "country")
head(bmi_all)
```
:::

# Multivariate analysis

In this section, we explore the Big Mac Index across various countries and years, examining its relationship with different economic indicators. Our goal is to identify patterns and understand the factors influencing the Big Mac price. We employ several statistical methods and visualizations:

1.  **Heatmap + Association Test:** exploratory data analysis (EDA) to graphically represent value of different indicators among countries, and investigate if any associations between higher Big Mac prices and other variables.

2.  **Treemap** + **ANOVA Test:** understand the distribution of diverse indicators across assorted regional clusters of countries, and employ ANOVA tests to determine if specific regions manifest statistically significant differences

3.  **Parallel Coordinates Plot (Paraplot):** Utilize parallel coordinates plots to visualize multi-dimensional relationships.

4.  **Correlation Analysis + Scatter Plot:** Explore the relationship between Big Mac prices and various economic indicators using correlation plots. Assess the strength and nature of correlations through scatter plots.

For each analysis, as an analyst, some consideration while conducting the explorations are:

1.  can I change the variables used?
2.  can I change the statistic method?
3.  can I change the aesthetics?

For each analysis, it will follow the flow of: starting with an exploratory data analysis, and to verify any discovery with a confirmatory analysis.

## **HEATMAP + ASSOCIATION TEST**

### **EDA - HEATMAP**

There are 2 methods taught in this class to plot a heatmap, using [heatmap()](https://www.rdocumentation.org/packages/stats/versions/3.6.0/topics/heatmap) of R stats package to plot a static heatmap, or using [**heatmaply**](http://talgalili.github.io/heatmaply/) package to plot an interactive heatmap. Given the dataset's complexity, with numerous countries and variables, interactivity enhances data exploration significantly. Interactive heatmaps allow users to hover over cells to reveal detailed information, offering a richer analysis experience compared to static heatmaps. For more insights and capabilities of **`heatmaply`**, refer to its [documentation](https://cran.r-project.org/web/packages/heatmaply/vignettes/heatmaply.html#is.na10-missing-values).

When crafting a heatmap, some parameters can be varied are:

1.  data transformation method
2.  change of data aggregation level
3.  change of grouped level
4.  change of display

#### Data Preparation

To accommodate diverse inputs such as aggregation method and group-by criteria, we design a function that dynamically processes the dataset based on user-defined parameters. This approach allows for flexibility in analyzing the data without resorting to hard coding.

The code chunk below takes in the dataframe, aggregation method, and group by method, the later 2 are dynamic input computed by the users. The code first prepares a list to accommodate five distinct aggregation methods. Subsequently, it groups the data based on the user-defined categorization, computing aggregated values for various economic indicators while excluding any null entries. The process yields an aggregated dataframe, which is then ready to serve as the basis for heatmap visualization.

```{r}
#| code-fold: false

aggregate_data <- function(data, agg_method, group_level) {
  
  agg_funcs <- list(
    mean = mean,
    max = max,
    min = min,
    median = median,
    var = var
  )
  
  aggregated_data <- data %>%
    group_by(.data[[group_level]]) %>%
    summarise(
      bmi_localprice = agg_funcs[[agg_method]](bmi_localprice, na.rm = TRUE),
      bmi_usd_price = agg_funcs[[agg_method]](bmi_usd_price, na.rm = TRUE),
      bmi_change = agg_funcs[[agg_method]](bmi_change, na.rm = TRUE),
      export_usd = agg_funcs[[agg_method]](export_usd, na.rm = TRUE),
      import_usd = agg_funcs[[agg_method]](import_usd, na.rm = TRUE),
      net_export = agg_funcs[[agg_method]](net_export, na.rm = TRUE),
      GDP = agg_funcs[[agg_method]](GDP, na.rm = TRUE),
      gdp_per_capita = agg_funcs[[agg_method]](gdp_per_capita, na.rm = TRUE),
      inflation = agg_funcs[[agg_method]](inflation, na.rm = TRUE),
      unemployment = agg_funcs[[agg_method]](unemployment, na.rm = TRUE),
      hdi = agg_funcs[[agg_method]](hdi, na.rm = TRUE),
      population = agg_funcs[[agg_method]](population, na.rm = TRUE)
    )
  
  return(aggregated_data)
}
```

#### Data Transformation Method

The package provides three distinct data transformation methods: normalize, scale, and percentile. These transformations are crucial, particularly in the context of our dataset, which spans a wide range of values across various economic indicators. Such disparity in data ranges can obfuscate direct comparisons. Employing these transformation methods enables a more coherent analysis, facilitating clearer comparisons by adjusting the data to a common scale. This is particularly beneficial when analyzing economic indicators, where differences in magnitude can significantly impact the interpretability of the data.

The code below created an aggregated dataframe with mean, grouped by different country and convert it into a matrix for ploting a heatmap with country as the unique indicator per row.

```{r}
#| code-fold: false
# create an aggregated dataframe
bmi_heatmap <- aggregate_data(bmi, "mean", "country")

# convert to a matrix
row.names(bmi_heatmap) <- bmi_heatmap$country
bmi_heatmap_matrix <- data.matrix(bmi_heatmap)
```

::: panel-tabset
## Scale - Column

```{r}
#| code-fold: false
heatmaply(bmi_heatmap_matrix,
          scale = "col")
```

## Scale - Row

```{r}
#| code-fold: false
heatmaply(bmi_heatmap_matrix,
          scale = "row")
```

## Normalize

```{r}
#| code-fold: false
heatmaply(normalize(bmi_heatmap_matrix))
```

## Percentile

```{r}
#| code-fold: false
heatmaply(percentize(bmi_heatmap_matrix))
```
:::

::: callout-important
## Insights on Argument Exposure

The experiments indicate that since the dataset ranges vary significantly (e.g., HDI is small a score while population figures are large), the percentile method emerges as the default choice for its ability to bin countries effectively.

The normalization and column scaling methods also provide insights by highlighting outliers and patterns, making them valuable options.

However, scaling by rows (countries) is less insightful due to its categorical nature and does not facilitate meaningful comparison across different indicators. Thus, all aggregation types should be made available for user exploration.

This inclusivity ensures a broader analytical scope, allowing users to discover outliers with scaling, uncover specific patterns through normalization, and categorize data effectively using the percentile approach.
:::

::: callout-tip
## Analysis Insights

Based on the percentile graph analysis, the local Big Mac price, especially in relation to changes grouped with inflation and population, suggests a potential association among these factors. This observation leads us to infer that the local price of a Big Mac could be closely linked with such factors. For the Big Mac price in USD, it is observed to group with the Human Development Index (HDI) and GDP per capita, indicating that, globally, it may be associated with such economic indicators.

An intriguing aspect of this analysis is the potential connection between the Big Mac price in USD with unemployment, and the change in Big Mac price with population.

To fully comprehend these associations, confirmatory data analysis (CDA) should be conducted. This deeper investigation will help in understanding the underlying patterns and relationships between the price of Big Macs and various economic indicators across different regions.
:::

#### Change of Aggregation Level

Employing different aggregation methods enriches the comparative analysis by highlighting various aspects of the economic indicators across countries. Specifically:

-   **Mean and Median**: These measures provide insights into the central tendency of the economic indicators, offering a snapshot of the typical or average values.

-   **Min and Max**: By showcasing the extremes, these aggregations reveal the full range of the data, from the lowest to the highest values.

-   **Variance**: This measure elucidates the variability or stability of each indicator within a country, indicating how dispersed the values are around the mean.

Each of these aggregation levels serves a distinct purpose in the analysis, allowing for a multifaceted understanding of the data. To explore these different perspectives, user should be able to simply adjust the aggregation method parameter in the function that prepares the data for heatmap visualization.

The code below compare with different aggregation method by changing the input into the function creating the heatmap matrix: `bmi_heatmap <- aggregate_data(bmi, "mean", "country")`

::: panel-tabset
## Mean

the code chunk below plot a heatmap aggregated at mean level

```{r}
#| code-fold: false
# create an aggregated dataframe
bmi_heatmap <- aggregate_data(bmi, "mean", "country")
# convert to a matrix
row.names(bmi_heatmap) <- bmi_heatmap$country
bmi_heatmap_matrix <- data.matrix(bmi_heatmap)
# plot the heatmap
heatmaply(percentize(bmi_heatmap_matrix))
```

## Median

the code chunk below plot a heatmap aggregated at median level

```{r}
#| code-fold: false
# create an aggregated dataframe
bmi_heatmap <- aggregate_data(bmi, "median", "country")
# convert to a matrix
row.names(bmi_heatmap) <- bmi_heatmap$country
bmi_heatmap_matrix <- data.matrix(bmi_heatmap)
# plot the heatmap
heatmaply(percentize(bmi_heatmap_matrix))
```

## Max

the code chunk below plot a heatmap aggregated at max level

```{r}
#| code-fold: false
# create an aggregated dataframe
bmi_heatmap <- aggregate_data(bmi, "max", "country")
# convert to a matrix
row.names(bmi_heatmap) <- bmi_heatmap$country
bmi_heatmap_matrix <- data.matrix(bmi_heatmap)
# plot the heatmap
heatmaply(percentize(bmi_heatmap_matrix))
```

## Min

the code chunk below plot a heatmap aggregated at min level

```{r}
#| code-fold: false
# create an aggregated dataframe
bmi_heatmap <- aggregate_data(bmi, "min", "country")

# convert to a matrix
row.names(bmi_heatmap) <- bmi_heatmap$country
bmi_heatmap_matrix <- data.matrix(bmi_heatmap)

# plot the heatmap
heatmaply(percentize(bmi_heatmap_matrix))
```

## Variance

the code chunk below plot a heatmap aggregated at variance level

```{r}
#| code-fold: false
# create an aggregated dataframe
bmi_heatmap <- aggregate_data(bmi, "var", "country")
# convert to a matrix
row.names(bmi_heatmap) <- bmi_heatmap$country
bmi_heatmap_matrix <- data.matrix(bmi_heatmap)
# plot the heatmap
heatmaply(percentize(bmi_heatmap_matrix))
```
:::

::: callout-important
## **Insights on Argument Exposure**

Exposing all aggregation methods offers valuable insights, particularly at the country level. It enables the discovery of specific patterns across different countries. For example, analyzing variance across indicators can illuminate the stability or volatility of each factor within nations, providing a deeper understanding of economic dynamics. Thus making all aggregation types—mean, median, max, min, and variance—available for exploration, users are empowered to conduct a thorough examination of the dataset from various angles. This flexibility facilitates a more nuanced analysis, allowing users to identify unique trends, outliers, and correlations that might not be apparent under a single aggregation approach.

Setting the mean as the default aggregation method, given its widespread acceptance as a fundamental measure of central tendency. It offers a solid starting point for initial explorations, from which users can then delve deeper into more specific or sophisticated analyses.
:::

#### Change of Grouped Level

The data supports two primary grouping levels: by country and by year, enabling cross-national or temporal comparisons. This versatility allows for nuanced comparisons across different nations or over time.

Similarly like aggregation methods, changing the **`group_level`** parameter in the function alters the heatmap visualization instead of hard coding it.

The code below compare with different group by method by changing the input into the function creating the heatmap matrix: `bmi_heatmap <- aggregate_data(bmi, "mean", "country")`. By experimenting with various scaling methods and grouping by year, we've assessed both mean and variance to elucidate the overarching trends of the variables over time and across countries. Only the best results are shown below.

::: panel-tabset
## year - mean

```{r}
#| code-fold: false
# create an aggregated dataframe
bmi_heatmap <- aggregate_data(bmi, "mean", 'year')
# convert to a matrix
row.names(bmi_heatmap) <- bmi_heatmap$year
bmi_heatmap_matrix <- data.matrix(bmi_heatmap)
# plot the heatmap
heatmaply(percentize(bmi_heatmap_matrix))
```

## year - variance

```{r}
#| code-fold: false
# create an aggregated dataframe
bmi_heatmap <- aggregate_data(bmi, "var", 'year')
# convert to a matrix
row.names(bmi_heatmap) <- bmi_heatmap$year
bmi_heatmap_matrix <- data.matrix(bmi_heatmap)
# plot the heatmap
heatmaply(normalize(bmi_heatmap_matrix))
```

## country

```{r}
#| code-fold: false
# create an aggregated dataframe
bmi_heatmap <- aggregate_data(bmi, "mean", 'country')
# convert to a matrix
row.names(bmi_heatmap) <- bmi_heatmap$country
bmi_heatmap_matrix <- data.matrix(bmi_heatmap)
# plot the heatmap
heatmaply(percentize(bmi_heatmap_matrix))
```
:::

::: callout-important
## Insights **on Argument Exposure**

The analysis framework enables exploration through two pivotal lenses: country and year. Grouping data by country provides a comprehensive, nation-wide analysis, while grouping by year illuminates outliers and temporal dynamics across nations. This dual perspective enriches our understanding of the interplay among various variables, facilitating exploratory data analysis (EDA) that empowers users to uncover and interpret patterns related to these variables. Given its broader applicability, grouping by country will be the default setting, acknowledging its prevalence in analytical explorations.
:::

::: callout-tip
## Analysis Insights

A particularly intriguing finding emerges from the year-by-year analysis, where we observe a mostly chronological arrangement of data points, reflecting national development and expected improvements in various indices over time. However, specific years stand out as outliers, notably 2009, 2010, and 2020. These years correspond to significant global events—the economic crisis of 2009 and the COVID-19 pandemic in 2020—highlighting their impact on the data.

Variance analysis across years shows which factors are most unstable across countries. For example, BMI variability was highest in 2011, inflation in 2019, and other factors varied greatly in 2021, demonstrating the value of this analysis for understanding fluctuations.

Additionally, BMI, net export and import are grouped based on dendrogram, leading to further investigation. This finding prompts us to explore how, beyond typical economic indicators, import and export values might specifically influence Big Mac prices through network analysis.
:::

#### Change of Display

Additional layout method allows the user to on or off the dendrogram by setting dendrogram augement between TRUE and FALSE

```{r}
# create an aggregated dataframe
bmi_heatmap <- aggregate_data(bmi, "mean", 'country')

# convert to a matrix
row.names(bmi_heatmap) <- bmi_heatmap$country
bmi_heatmap_matrix <- data.matrix(bmi_heatmap)
```

::: panel-tabset
## with dendrogram

```{r}
#| code-fold: false

# plot the heatmap
heatmaply(percentize(bmi_heatmap_matrix), 
          dendrogram = TRUE)
```

## without dendrogram

```{r}
#| code-fold: false
# plot the heatmap
heatmaply(percentize(bmi_heatmap_matrix), 
          dendrogram = FALSE)
```
:::

::: callout-important
## Insights **on Argument Exposure**

Given that the dendrogram assists in the initial clustering of countries and variables, offering a hierarchical view of the data, it is recommended to be enabled by default for enhanced analytical depth. This feature enriches the user's ability to discern patterns and relationships within the data, facilitating a more intuitive understanding of complex datasets.
:::

#### Summary

Based on the above experiment, the plot should allow for the functions below to provide enough flexibility for user to conduct statistical exploratory data analysis (EDA) to have a general idea on overall value range and discern potential relationships among variables. With this preliminary EDA, users can subsequently delve into comparative data analysis (CDA) targeting specific variables to test hypotheses.

Key Features for Comprehensive Analysis:

-   **Grouping Method**: Options include by year or country, facilitating targeted analysis.

-   **Aggregation Level**: Supports mean, median, max, min, and variance to accommodate different analytical needs.

-   **Transformation Setting**: Allows scaling, normalization, or percentile-based adjustments for data preparation.

-   **Aesthetic Setting**: Offers the ability to toggle the dendrogram on or off, enhancing visual clarity.

These features ensure that users have the necessary tools to perform robust statistical analysis, laying the groundwork for more complex investigations.

For seamless backend integration, the API setup includes functionalities that cater to diverse analytical preferences below

::: callout-caution
## Summary - API set up

Modifying Input Dataframe: aggregate_data(data, aggregation_by, group_by)

-   group_by: year(default), country

-   aggregation_by: mean(default), median, max, min, var

Modifying heatmaply():

-   transformation:

    -   scale: heatmaply(data, scale = "col")

    -   percentile(default): heatmaply(percentize(data))

    -   normalize: heatmaply(normalize(data))

Modifying augement in heatmaply():

-   dendrogram: TRUE(default), FALSE
:::

### **CDA - ASSOCIATION**

after visualizing it on the heatmap, association test can be conducted to verrify the initial hypothesis discovered from the heatmap, in particualr, if there is association betwwen any variable with our target Big mac index, either local or in usd.

association test is sleected becuase based on our eda above, most of the varibales are using precentile/bined, as the range of our vartiblrs much, binning into different bin might provde more insights to our analysis in our context .

[ggstatsplot](https://indrajeetpatil.github.io/ggstatsplot/index.html) package supports the ploting and conduct of association test., the package is chopsen due to its flexibility in its rich range of augement supoporting different ststaical test methods, and other fine tuyning about the test. the documnettaion is <https://indrajeetpatil.github.io/ggstatsplot/reference/ggbarstats.html>

When conducting the cda, some parameters can be varied are:

1.  input related: variables to compre with, bining methon, bin size

2.  tesingrealted: statictal test type, confidence level

3.  aesthitic: in % or count

```{r}
plot_binned_association <- function(data, col1, col2, n_bins) {
  # Binning both columns
  bins_col1 <- cut(data[[col1]], breaks = n_bins, labels = paste("Bin", 1:n_bins))
  bins_col2 <- cut(data[[col2]], breaks = n_bins, labels = paste("Bin", 1:n_bins))
  
  # Creating a temporary dataframe with binned columns
  temp_data <- data.frame(bins_col1, bins_col2)
  
  # Plotting using ggbarstats
  ggbarstats(
    data = temp_data,
    x = bins_col1,
    y = bins_col2,
    title = paste("Association between binned", col1, "and", col2)
  )
}
```

::: panel-tabset
## bmi_usd_price & hdi

In this code chunk below [*ggbarstats()*](https://indrajeetpatil.github.io/ggstatsplot/reference/ggbarstats.html) is used to build a visual for Significant Test of Association with different input

```{r}
plot_binned_association(bmi_heatmap, "bmi_usd_price", "hdi", 4)
```

## bmi_usd_price & hdi

```{r}
plot_binned_association(bmi_heatmap, "bmi_usd_price", "gdp_per_capita", 3)
```
:::

## **TREE MAP + ANOVA TEST**

### **TREE MAP**

#### Data Preperation

```{r}
aggregate_data <- function(data, agg_method, group_levels) {
  agg_funcs <- list(
    mean = mean,
    max = max,
    min = min,
    median = median,
    var = var
  )
  
  # Ensuring group_levels is a character vector
  if(is.character(group_levels)) {
    group_levels <- syms(group_levels)
  } else {
    stop("group_levels should be a vector of column names.")
  }
  
  aggregated_data <- data %>%
    group_by(!!!group_levels) %>%
    summarise(
      bmi_localprice = agg_funcs[[agg_method]](bmi_localprice, na.rm = TRUE),
      bmi_usd_price = agg_funcs[[agg_method]](bmi_usd_price, na.rm = TRUE),
      export_usd = agg_funcs[[agg_method]](export_usd, na.rm = TRUE),
      import_usd = agg_funcs[[agg_method]](import_usd, na.rm = TRUE),
      net_export = agg_funcs[[agg_method]](net_export, na.rm = TRUE),
      GDP = agg_funcs[[agg_method]](GDP, na.rm = TRUE),
      gdp_per_capita = agg_funcs[[agg_method]](gdp_per_capita, na.rm = TRUE),
      inflation = agg_funcs[[agg_method]](inflation, na.rm = TRUE),
      unemployment = agg_funcs[[agg_method]](unemployment, na.rm = TRUE),
      hdi = agg_funcs[[agg_method]](hdi, na.rm = TRUE),
      population = agg_funcs[[agg_method]](population, na.rm = TRUE),
      .groups = 'drop'
    )
  
  return(aggregated_data)
}

```

#### group by different country

::: panel-tabset
## continent

```{r}
bmi_heatmap <- aggregate_data(bmi_all, "mean", c("continent", "country"))

treemap(bmi_heatmap,
        index = c("continent", "country"),
        vSize = "bmi_usd_price",
        vColor = "population",
        title = "BMI USD Price and Population by Continent and Country",
        palette = "RdYlBu",
        title.legend = "Population")
```

## g20

```{r}
bmi_heatmap <- aggregate_data(bmi_all, "mean", c("g20", "country"))

treemap(bmi_heatmap,
        index = c("g20", "country"),
        vSize = "bmi_usd_price",
        vColor = "population",
        title = "BMI USD Price and Population by Continent and Country",
        palette = "RdYlGn",
        title.legend = "Population")
```
:::

#### different type of aggregation

::: panel-tabset
## mean

```{r}
bmi_heatmap <- aggregate_data(bmi_all, "mean", c("continent", "country"))

treemap(bmi_heatmap,
        index = c("continent", "country"),
        vSize = "bmi_usd_price",
        vColor = "population",
        title = "BMI USD Price and Population by Continent and Country",
        palette = "RdYlBu",
        title.legend = "Population")
```

## variance

```{r}
bmi_heatmap <- aggregate_data(bmi_all, "var", c("continent", "country"))

treemap(bmi_heatmap,
        index = c("continent", "country"),
        vSize = "bmi_usd_price",
        vColor = "population",
        title = "BMI USD Price and Population by Continent and Country",
        palette = "RdYlGn",
        title.legend = "Population")
```
:::

to visualize with different variables

::: panel-tabset
## bmi_usd & population

```{r}
bmi_heatmap <- aggregate_data(bmi_all, "mean", c("continent", "country"))

treemap(bmi_heatmap,
        index = c("continent", "country"),
        vSize = "bmi_usd_price",
        vColor = "population",
        title = "BMI USD Price and Population by Continent and Country",
        palette = "RdYlGn",
        title.legend = "Population")
```

## gdp_per_capita & bmi_usd

```{r}
bmi_heatmap <- aggregate_data(bmi_all, "mean", c("continent", "country"))

treemap(bmi_heatmap,
        index = c("continent", "country"),
        vSize = "gdp_per_capita",
        vColor = "bmi_usd_price",
        title = "BMI USD Price and Population by Continent and Country",
        palette = "RdYlGn",
        title.legend = "Population")
```
:::

### **ANOVA TEST**

with this, we can conduct anova test to test on our hypothesis from the eda above, if a certain countries have higher bmi, or other indicators than other countries

compare different locations

In the code chunk below, [*ggbetweenstats()*](https://indrajeetpatil.github.io/ggstatsplot/reference/ggbetweenstats.html) is used to build a visual for One-way ANOVA test on English score by race. <https://indrajeetpatil.github.io/ggstatsplot/reference/ggbetweenstats.html#centrality-measures>

::: panel-tabset
## g20

```{r}
ggbetweenstats(
  data = bmi_all,
  x = g7, 
  y = bmi_usd_price,
  type = "p",
  mean.ci = TRUE, 
  pairwise.comparisons = TRUE, 
  pairwise.display = "s",
  p.adjust.method = "fdr",
  messages = FALSE
)
```

## continent

```{r}
ggbetweenstats(
  data = bmi_all,
  x = continent, 
  y = bmi_usd_price,
  type = "p",
  mean.ci = TRUE, 
  pairwise.comparisons = TRUE, 
  pairwise.display = "s",
  p.adjust.method = "fdr",
  messages = FALSE
)
```
:::

or zoom into a particular group of countries

::: panel-tabset
## asia

```{r}
bmi_all_filter <- filter(bmi_all, continent == "Asia")
ggbetweenstats(
  data = bmi_all_filter,
  x = country, 
  y = bmi_usd_price,
  type = "p",
  mean.ci = TRUE, 
  pairwise.comparisons = TRUE, 
  pairwise.display = "s",
  p.adjust.method = "fdr",
  messages = FALSE
)
```

## europe

```{r}
bmi_all_filter <- filter(bmi_all, continent == "Europe")
ggbetweenstats(
  data = bmi_all_filter,
  x = country, 
  y = bmi_usd_price,
  type = "p",
  mean.ci = TRUE, 
  pairwise.comparisons = TRUE, 
  pairwise.display = "s",
  p.adjust.method = "fdr",
  messages = FALSE
)
```

## G7

```{r}
bmi_all_filter <- filter(bmi_all, g7  == TRUE)
ggbetweenstats(
  data = bmi_all_filter,
  x = country, 
  y = bmi_usd_price,
  type = "p",
  mean.ci = TRUE, 
  pairwise.comparisons = TRUE, 
  pairwise.display = "s",
  p.adjust.method = "fdr",
  messages = FALSE
)
```
:::

change on sign. level

::: panel-tabset
## 95 sign. level

```{r}
bmi_all_filter <- filter(bmi_all, g7  == TRUE)
ggbetweenstats(
  data = bmi_all_filter,
  x = country, 
  y = bmi_usd_price,
  type = "p",
  mean.ci = TRUE, 
  pairwise.comparisons = TRUE, 
  pairwise.display = "s",
  p.adjust.method = "fdr",
  messages = FALSE,
  conf.level = 0.95
)
```

## 99 sign. level

```{r}
bmi_all_filter <- filter(bmi_all, g7  == TRUE)
ggbetweenstats(
  data = bmi_all_filter,
  x = country, 
  y = bmi_usd_price,
  type = "p",
  mean.ci = TRUE, 
  pairwise.comparisons = TRUE, 
  pairwise.display = "s",
  p.adjust.method = "fdr",
  messages = FALSE,
  conf.level = 0.95
)
```
:::

display

::: panel-tabset
## all

```{r}
bmi_all_filter <- filter(bmi_all, g7  == TRUE)
ggbetweenstats(
  data = bmi_all_filter,
  x = country, 
  y = bmi_usd_price,
  type = "p",
  mean.ci = TRUE, 
  pairwise.comparisons = TRUE, 
  pairwise.display = "all",
  p.adjust.method = "fdr",
  messages = FALSE,
  conf.level = 0.95
)
```

## non

```{r}
bmi_all_filter <- filter(bmi_all, g7  == TRUE)
ggbetweenstats(
  data = bmi_all_filter,
  x = country, 
  y = bmi_usd_price,
  type = "p",
  mean.ci = TRUE, 
  pairwise.comparisons = TRUE, 
  pairwise.display = "none",
  p.adjust.method = "fdr",
  messages = FALSE,
  conf.level = 0.95
)
```

## significant

```{r}
bmi_all_filter <- filter(bmi_all, g7  == TRUE)
ggbetweenstats(
  data = bmi_all_filter,
  x = country, 
  y = bmi_usd_price,
  type = "p",
  mean.ci = TRUE, 
  pairwise.comparisons = TRUE, 
  pairwise.display = "s",
  p.adjust.method = "fdr",
  messages = FALSE,
  conf.level = 0.95
)
```

## no significant

```{r}
bmi_all_filter <- filter(bmi_all, g7  == TRUE)
ggbetweenstats(
  data = bmi_all_filter,
  x = country, 
  y = bmi_usd_price,
  type = "p",
  mean.ci = TRUE, 
  pairwise.comparisons = TRUE, 
  pairwise.display = "ns",
  p.adjust.method = "fdr",
  messages = FALSE,
  conf.level = 0.95
)
```
:::

test method

-   `"parametric"`

-   `"nonparametric"`

-   `"robust"`

-   `"bayes"`

::: panel-tabset
## parametric

```{r}
bmi_all_filter <- filter(bmi_all, g7  == TRUE)
ggbetweenstats(
  data = bmi_all_filter,
  x = country, 
  y = bmi_usd_price,
  type = "p",
  mean.ci = TRUE, 
  pairwise.comparisons = TRUE, 
  pairwise.display = "s",
  p.adjust.method = "fdr",
  messages = FALSE,
  conf.level = 0.95
)
```

## Non parametric

```{r}
bmi_all_filter <- filter(bmi_all, g7  == TRUE)
ggbetweenstats(
  data = bmi_all_filter,
  x = country, 
  y = bmi_usd_price,
  type = "np",
  mean.ci = TRUE, 
  pairwise.comparisons = TRUE, 
  pairwise.display = "s",
  p.adjust.method = "fdr",
  messages = FALSE,
  conf.level = 0.95
)
```

## robust

```{r}
bmi_all_filter <- filter(bmi_all, g7  == TRUE)
ggbetweenstats(
  data = bmi_all_filter,
  x = country, 
  y = bmi_usd_price,
  type = "r",
  mean.ci = TRUE, 
  pairwise.comparisons = TRUE, 
  pairwise.display = "s",
  p.adjust.method = "fdr",
  messages = FALSE,
  conf.level = 0.95
)
```

## bayes

```{r}
bmi_all_filter <- filter(bmi_all, g7  == TRUE)
ggbetweenstats(
  data = bmi_all_filter,
  x = country, 
  y = bmi_usd_price,
  type = "b",
  mean.ci = TRUE, 
  pairwise.comparisons = TRUE, 
  pairwise.display = "s",
  p.adjust.method = "fdr",
  messages = FALSE,
  conf.level = 0.95
)
```
:::

### **PARAPLOT**

paraplot can reporesent the relationship between multiple variables by, the pro of using it is to ....

the library used here is [`ggparcoord()`](https://ggobi.github.io/ggally/reference/ggparcoord.html) from GGally.

```{r}
pacman::p_load(GGally)
```

for each plot, i want to

1.  to able to select group by level, countries, years, regions etc.
2.  choose scale method
3.  control the line intensity
4.  on/off the boxplot
5.  plot in one aggregated manner, or facet

#### Control Group by Level

::: panel-tabset
## country

```{r}
ggparcoord(data = bmi_all, 
           columns = c(4:15), 
           groupColumn = 1,
           scale = "uniminmax",
           alphaLines = 0.2,
           boxplot = TRUE)
```

## year

```{r}
bmi_all_new <- bmi_all
bmi_all_new$year <- factor(bmi_all_new$year, levels = sort(unique(bmi_all_new$year)))

ggparcoord(data = bmi_all_new, 
           columns = c(4:15), 
           groupColumn = 2,
           scale = "uniminmax",
           alphaLines = 0.2,
           boxplot = TRUE)
```

## continent

```{r}
ggparcoord(data = bmi_all, 
           columns = c(4:15), 
           groupColumn = 16,
           scale = "uniminmax",
           alphaLines = 0.2,
           boxplot = TRUE)
```
:::

to on/off boxplot

::: panel-tabset
## without boxplot

```{r}
ggparcoord(data = bmi_all, 
           columns = c(4:15), 
           groupColumn = 16,
           scale = "uniminmax",
           alphaLines = 0.2)
```

## with boxplot

```{r}
ggparcoord(data = bmi_all, 
           columns = c(4:15), 
           groupColumn = 16,
           scale = "uniminmax",
           alphaLines = 0.2,
           boxplot = TRUE)
```
:::

to change on scale method

::: panel-tabset
## std

```{r}
ggparcoord(data = bmi_all, 
           columns = c(4:15), 
           groupColumn = 16,
           scale = "std",
           alphaLines = 0.2,
           boxplot = TRUE)
```

## robust (not applicable)

```{r}
ggparcoord(data = bmi_all, 
           columns = c(4:15), 
           groupColumn = 16,
           scale = "robust",
           alphaLines = 0.2,
           boxplot = TRUE)
```

## uniminmax

```{r}
ggparcoord(data = bmi_all, 
           columns = c(4:15), 
           groupColumn = 16,
           scale = "uniminmax",
           alphaLines = 0.2,
           boxplot = TRUE)
```

## globalminmax (not applicable)

```{r}
ggparcoord(data = bmi_all, 
           columns = c(4:15), 
           groupColumn = 16,
           scale = "globalminmax",
           alphaLines = 0.2,
           boxplot = TRUE)
```

## center

```{r}
ggparcoord(data = bmi_all, 
           columns = c(4:15), 
           groupColumn = 16,
           scale = "center",
           alphaLines = 0.2,
           boxplot = TRUE)
```

## cenerObs

```{r}
ggparcoord(data = bmi_all, 
           columns = c(4:15), 
           groupColumn = 16,
           scale = "centerObs",
           alphaLines = 0.2,
           boxplot = TRUE)
```
:::

to draw on an aggregated diagram or a facet

::: panel-tabset
## aggregated

```{r}
ggparcoord(data = bmi_all, 
           columns = c(4:15), 
           groupColumn = 16,
           scale = "uniminmax",
           alphaLines = 0.2,
           boxplot = TRUE) + 
  theme(axis.text.x = element_text(angle = 30))
```

## Facet

```{r}
ggparcoord(data = bmi_all, 
           groupColumn = 16,
           columns = c(4:15), 
           scale = "uniminmax",
           alphaLines = 0.2,
           boxplot = TRUE) +
  facet_wrap(~ continent) + 
  theme(axis.text.x = element_text(angle = 30))
```
:::

based on the experiment above, countries having different patterns, on the same plot, it looks very hard to differentiate from different countries, thus a facet should be used instead of an aggregated version.

### **CORRELATION**

For the correlation analysis, we utilize the [corrplot package](https://cran.r-project.org/web/packages/corrplot/vignettes/corrplot-intro.html), which is designed specifically for visualizing correlation matrices. This methodology is designed to offer users comprehensive flexibility in their exploratory analysis, enabling them to uncover patterns and relationships within the data through interactive exploration. Key features of this refined approach include:

1.  Choice of Correlation Coefficient

2.  Data Filtering Capabilities

3.  Aggregated and Faceted Analysis

4.  Display Customization

#### Data Preperation

All variables used in the correlation analysis must be numerical. The code below select numerical and country column.

```{r}
bmi_numeric <- bmi %>%
  select(country, where(is.numeric))
```

#### Choice of Correlation Coefficient

Users can select the type of statistical correlation coefficient for their analysis, such as Pearson, Spearman, or Kendall. This selection allows for the adaptation of the analysis to the nature of the data and the specific relationships of interest.

Three types of correlation coefficients can be specified using the **`method`** argument in the **`cor()`** function:

-   **Pearson:** The default method, suitable for linear relationships, calculating the linear dependence between variables.

-   **Kendall:** A non-parametric test that measures the ordinal association between variables.

-   **Spearman:** A non-parametric test that assesses how well the relationship between two variables can be described using a monotonic function.

::: panel-tabset
## Pearson

The code chunk below demonstrates the use of the Pearson method.

```{r}
bmi.cor <- cor(bmi_numeric[-1],method = "pearson",use = "complete.obs")
corrplot(bmi.cor,
         diag = FALSE,
         tl.col = "black")
```

## Kendall

The code chunk below demonstrates the use of the Kendall method.

```{r}
bmi.cor <- cor(bmi_numeric[-1],method = "kendall", use = "complete.obs")
a <- corrplot(bmi.cor,
         diag = FALSE,
         tl.col = "black")

```

## Spearman

tThe code chunk below demonstrates the use of the Spearman method.

```{r}
bmi.cor <- cor(bmi_numeric[-1],method = "spearman", use = "complete.obs")
corrplot(bmi.cor,
         diag = FALSE,
         tl.col = "black")
```
:::

Among these three, Pearson is the most commonly used method for calculating correlation efficiency. It's set as a input variable, allowing users to switch between different methods.

#### Data Filtering Capabilities

To hone in on relevant insights, users can filter the input data based on specific criteria, such as particular countries, ranges of years, or predefined groups. This targeted analysis helps in isolating the effects and relationships that are most pertinent to the user's research questions.

Additionally, zooming into specific years or countries can provide more focused analysis. To facilitate this:

-   filtering specific years

-   filtering specific countries

-   filtering group of countries

Setting selected columns as variables makes adjustments easier. Below, the column and input are set as variables:

```{r}
x_col <- "year"  
x_input <- "2020"  

filtered_data <- bmi_numeric %>%
  filter(.data[[x_col]] == x_input) %>% 
  select(-.data[[x_col]]) 
```

::: panel-tabset
## Filter by Year

```{r}
x_col <- "year"  
x_input <- "2020"  

filtered_data <- bmi_numeric %>%
  filter(.data[[x_col]] == x_input) %>% 
  select(-.data[[x_col]]) 

bmi.cor <- cor(filtered_data[-1],method = "pearson")
corrplot(bmi.cor,
         diag = FALSE,
         tl.col = "black")
```

## Filter By Country

```{r}
x_col <- "country"  
x_input <- "China"  

filtered_data <- bmi_numeric %>%
  filter(.data[[x_col]] == x_input) %>% 
  select(-.data[[x_col]]) 

bmi.cor <- cor(filtered_data[-1],method = "pearson")
corrplot(bmi.cor,
         diag = FALSE,
         tl.col = "black")
```
:::

filter by continent

To compare 2 countries stat: for example, China, and Russia

```{r}
filtered_data <- bmi %>% 
  filter(country %in% c('Russia', 'Singapore'))
```

After have a quick EDA on the correlations, it makes more sense to zoom into 2 variables to understand the correlation in greater details

#### Aggregated and Faceted Analysis

The framework supports both a holistic view of the data through aggregated correlation matrices and a more detailed exploration via faceted analysis. This dual approach permits users to view overall patterns at a glance and then drill down into subgroup-specific relationships for more nuanced insights.

#### Display CustomizationUsers

have the ability to adjust various display parameters of the correlation matrices, including color schemes, annotation options, and the ordering of variables. This customization enhances the interpretability of the visualizations and allows users to tailor the output to their specific analytical and presentation needs.

#### Summary

::: callout-note
## Argument

Type of Comparison:

-   Compare

-   

Input:

-   year

-   countries

Augment:

Aesthetic:

-   representation - method: 'circle', 'square', 'ellipse', 'number', 'shade', 'color', 'pie'

-   layout - type: 'full', 'upper', 'lower'

-   order: 'AOE', 'FPC', 'hclust', 'alphabet'

-   diag = FALSE

-   lower = "ellipse",

-   upper = "number",
:::

```{r}
#| fig-width: 10
#| fig-height: 10
bmi.cor <- cor(bmi_numeric[-1],method = "spearman", use = "complete.obs")
corrplot.mixed(bmi.cor,
               lower = "ellipse", 
               upper = "number",
               tl.pos = "lt",
               diag = "l",
               tl.col = "black")

```

Investigate how different numerical variables relate to each other. For instance, you could look at the correlation between **`bmi_usd_price`** and **`GDP_per_capita`** or between **`bmi_gdpadj_price`** and **`inflation`**. This can be done using Pearson or Spearman correlation coefficients depending on the data distribution.

#### Comparision with Variables

Analyzing data across all years and countries may not yield insightful patterns. It is often more interesting to conduct exploratory data analysis (EDA) to understand if there are patterns in different countries, years, or groups of countries. This involves creating facets by different filters:

-   group by years

-   group by countries

-   group by economic groups

To facilitate ease of changes, it's necessary to set these selected groupings as variable inputs. The code chunk below assigns the column and the input as variables:

set filter

```{r}
grouping_var_name <- "country" # Change this to "year" or any other column name as needed
filter_region <- "Asia" # Assuming there's a 'region' column that includes this information
filter_year1 <- 2005
filter_year2 <- 2021

```

```{r}
# Filter dataset for Asian countries and the years 2005 to 2021
filtered_data <- bmi_all %>%
  filter(continent == filter_region & year %in% c(2009, 2021))
```

```{r}
#| fig-width: 16
#| fig-height: 8
# Now use this filtered data in grouped_ggcorrmat, with dynamic grouping
grouped_ggcorrmat(
  data = filtered_data,
  cor.vars = 3:11, # Adjust as per your dataset structure
  use = "pairwise.complete.obs",
  grouping.var = factor(year),
  plotgrid.args = list(ncol = 4),
  ggcorrplot.args = list(outline.color = "black", 
                         hc.order = TRUE,
                         tl.cex = 10)
)
```

compare between 2 countries

```{r}
filtered_data <- bmi_all %>%
  filter(country  %in% c("China", "Singapore"))
```

```{r}
#| fig-width: 16
#| fig-height: 8
grouped_ggcorrmat(
  data = filtered_data,
  cor.vars = 3:11, # Adjust as per your dataset structure
  use = "pairwise.complete.obs",
  grouping.var = country,
  plotgrid.args = list(ncol = 4),
  ggcorrplot.args = list(outline.color = "black", 
                         hc.order = TRUE,
                         tl.cex = 10)
)
```

### Scatter Plot

For pairs of variables with higher correlation, you can first visualize their relationship more closely using scatter plots and then perform statistical tests to evaluate the significance of these correlations.

use the **`ggstatsplot`** package to both visualize and perform significance testing on your data. The **`ggstatsplot`** package is designed to create graphics with details from statistical tests included automatically, making it a powerful tool for exploratory data analysis and for presenting statistical findings.

to visualize the relationship between **`gdp_per_capita`** and **`bmi_usd_price`**, including a significance test for their correlation.

```{r}
ggscatterstats(
  data = bmi_all,
  x = gdp_per_capita,
  y = bmi_usd_price,
  marginal = FALSE,
  )

```

Summary

::: callout-note
## arguments

-   test method

-   significant test

-   x & y
:::

### **Display Significance Testing Results**

To statistically test the significance of the correlation between these two variables, you can use the **`cor.test()`** function in R, which not only gives the correlation coefficient but also provides a p-value indicating whether the observed correlation is statistically significant.

```{r}
cor.test_result <- cor.test(bmi$gdp_per_capita, bmi$bmi_usd_price, method = "pearson")
print(cor.test_result)

```

# Time Series Clustering

time series clustering is a technique xxxx

### **Installing and launching R packages**

package [dtwclust](https://cran.r-project.org/web/packages/dtwclust/index.html) is used

```{r}
pacman::p_load(dtwclust)
```

## Model Calibration

1.  input: columns to be imputed into the clustering
2.  type of clustering: types Clustering types. It must be any combination of (possibly abbreviated): "partitional"(k-means), "hierarchical", "fuzzy", "tadpole.". 2 of the most common clustering types will be explored here: "partitional"(k-means), and "hierarchical"
3.  seed, with a default setting as 2024, while allowing the user to change to its own seed for reproduction
4.  number of cluster k

### **Data Preparation**

input a list of columns for the model, filter column for analysis, default is using all numerical columns

```{r}
df_selected <- bmi_numeric
```

First, reshape the data to a wide format where each row represents a country and each column represents a year with its corresponding Big Mac Index price in USD. You've already started this step, so let's continue from there, ensuring each time series is properly formatted for clustering.

### **Convert Data to Time Series Objects**

Convert each row into a time series object. This is essential because the clustering algorithm requires time series data to measure similarities.

```{r}
df_selected_imputed <- df_selected
numeric_columns <- sapply(df_selected_imputed, is.numeric)
df_selected_imputed[numeric_columns] <- lapply(df_selected_imputed[numeric_columns], function(x) {
  ifelse(is.na(x), mean(x, na.rm = TRUE), x)
})
```

### **Perform Time Series Clustering**

Now, you're ready to cluster the time series data. You can adjust the number of clusters (**`k`**) and other parameters based on your specific needs.

Using Different Type

::: panel-tabset
## k-means

```{r}
# Clustering using DTW (Dynamic Time Warping)
clustering_result <- tsclust(df_selected_imputed[,-1], type = "partitional", k = 4, distance = "dtw")

# Extract cluster assignments
cluster_assignments <- sapply(clustering_result@cluster, function(x) x)
```

visualizing the cluster with a scatter plot

```{r}
pca_result <- prcomp(df_selected_imputed[,-1], scale. = TRUE)
df_pca <- as.data.frame(pca_result$x)

# Add cluster assignments to the PCA results dataframe
df_pca$cluster <- cluster_assignments

# Scatter plot of the first two principal components colored by cluster assignment
ggplot(df_pca, aes(x = PC1, y = PC2, color = as.factor(cluster))) +
  geom_point() +
  labs(title = "K-means Clustering Results with PCA", color = "Cluster") +
  theme_minimal()
```

## hierarchical

```{r}
# Clustering using DTW (Dynamic Time Warping)
clustering_result <- tsclust(df_selected_imputed[,-1], type = "hierarchical", k = 4, distance = "dtw")

# Extract cluster assignments
cluster_assignments <- sapply(clustering_result@cluster, function(x) x)
```

visualizing the cluster with a dendrogram

```{r}
# Assuming clustering_result is from hierarchical clustering
plot(clustering_result, type = "dendrogram")

```
:::

another way to calibrate is the number of groups, with a different k = 3

```{r}
# Clustering using DTW (Dynamic Time Warping)
clustering_result <- tsclust(df_selected_imputed[,-1], type = "partitional", k = 3, distance = "dtw")

# Extract cluster assignments
cluster_assignments <- sapply(clustering_result@cluster, function(x) x)
```

```{r}
pca_result <- prcomp(df_selected_imputed[,-1], scale. = TRUE)
df_pca <- as.data.frame(pca_result$x)

# Add cluster assignments to the PCA results dataframe
df_pca$cluster <- cluster_assignments

# Scatter plot of the first two principal components colored by cluster assignment
ggplot(df_pca, aes(x = PC1, y = PC2, color = as.factor(cluster))) +
  geom_point() +
  labs(title = "K-means Clustering Results with PCA", color = "Cluster") +
  theme_minimal()
```

## Visualization of model

To better understand and visualize the clustering results, consider plotting the Big Mac Index prices in USD for each country, colored by their cluster assignment. This step can provide insights into the similarities within each cluster.

### **Clusters Back to Countries**

After obtaining the cluster assignments, map these back to the countries to identify which countries have been grouped together.

# Combine cluster assignments with country names

clustered_countries \<- data.frame(country = country_names, cluster = cluster_assignments)

# View the cluster assignments

print(clustered_countries)

plot and display the number of countries in each

plot the trends for countries from different clusters

# Merge the cluster assignments back with the original data

# df_clustered \<- merge(df_selected, clustered_countries, by = "country")

# Plot

''' ggplot(df_clustered, aes(x = year, y = bmi_usd_price, group = country, color = factor(cluster))) + geom_line() + theme_minimal() + labs(title = "Time Series Clustering of Big Mac Index Prices by Country", color = "Cluster")

'''

adjustable parameters:

-   input:

    -   target variables for clustering

    -   timeframe for analysis

-   model calibration:

    -   type of clustering method to use: **`"partitional"`**, **`"hierarchical"`**, **`"tadpole"`** or **`"fuzzy"`**

    -   k: Number of desired clusters. It can be a numeric vector with different values

<https://rdrr.io/cran/dtwclust/man/tsclust.html>

<https://www.rdocumentation.org/packages/dtwclust/versions/5.5.12>

<https://cran.r-project.org/web/packages/dtwclust/dtwclust.pdf>

geo spatial analysis to visualize the location of such countries by cluster on the world map directly, to understand its geospatial location, if there is any pattern

to find out more about geo-spatial portion, please refer to our team mate's work xxxx

can we predict the behaviour of countries without big mac data ?
