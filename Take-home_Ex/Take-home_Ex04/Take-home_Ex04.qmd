---
title: "Take-home Exercise 4"
author: "Li Jiayi"
date: "03/06/24"
date-modified: "last-modified"
execute:
  eval: true
  echo: true 
  warning: false
  freeze: true
code-fold: true
code-summary: "Show the code"
date-format: long
---

# Project Component

This project have the following the component:

1.  Uni-Vraiant & Time series Analysis
2.  Multi-Variant Analysis
3.  Geospatial Analysis
4.  Modeling
    -   Panel Regression
    -   Network Analysis
    -   Time Series Clustering

This take home exercise will cover on Multi-Variant Analysis, and Time Series Clustering.

# Data Preparation

Please refer to [this link](https://isss608-24jan-group1.netlify.app/prototype/data_preparation/data_preparation) for the complete data preparation process contributed by all team members. The final dataset within the group.

## Loading R packages

```{r}
#| code-fold: false
pacman::p_load(ggiraph, plotly, tidyverse,
               corrplot, ggstatsplot,ggraph, igraph, 
               heatmaply, treemap, dplyr,GGally)
```

## **Importing Data**

The code below uses the **`read_csv()`** function from the **readr** package to import **`bmi_data.csv`** and **`country_data.csv`** into the environment.

```{r}
#| code-fold: false
bmi <- read_csv("data/bmi_data.csv")
country <- read_csv("data/country_data.csv")
```

Two datasets are used: **`bmi_data`** contains the target variable, Big Mac Index, and a list of economic indicators from 28 countries and regions for the years 2002 to 2022. This data has already been cleaned and manipulated for analysis. **`country_data`** contains geographical and economic category groups for the 28 countries and regions involved, such as EU, continent, and G20 etc.

::: panel-tabset
## BMI

```{r}
#| code-fold: false
head(bmi)
```

## Region

```{r}
#| code-fold: false
head(country)
```

## Combined

Left join country with bmi data by country name, and take a preview of the data

```{r}
#| code-fold: false
bmi_all <- left_join(bmi, country, by = "country")
head(bmi_all)
```
:::

# Multivariate analysis

In this section, we explore the Big Mac Index across various countries and years, examining its relationship with different economic indicators. Our goal is to identify patterns and understand the factors influencing the Big Mac price. We employ several statistical methods and visualizations:

1.  **Heatmap + Association Test:** exploratory data analysis (EDA) to graphically represent value of different indicators among countries, and investigate if any associations between higher Big Mac prices and other variables.

2.  **Treemap** + **ANOVA Test:** understand the distribution of diverse indicators across assorted regional clusters of countries, and employ ANOVA tests to determine if specific regions manifest statistically significant differences

3.  **Parallel Coordinates Plot (Paraplot):** Utilize parallel coordinates plots to visualize multi-dimensional relationships.

4.  **Correlation Analysis + Scatter Plot:** Explore the relationship between Big Mac prices and various economic indicators using correlation plots. Assess the strength and nature of correlations through scatter plots.

For each analysis, as an analyst, some consideration while conducting the explorations are:

1.  can I change the variables used?
2.  can I change the statistic method?
3.  can I change the aesthetics?

For each analysis, it will follow the flow of: starting with an exploratory data analysis, and to verify any discovery with a confirmatory analysis.

## **HEATMAP + ASSOCIATION TEST**

### **EDA - HEATMAP**

There are 2 methods taught in this class to plot a heatmap, using [heatmap()](https://www.rdocumentation.org/packages/stats/versions/3.6.0/topics/heatmap) of R stats package to plot a static heatmap, or using [**heatmaply**](http://talgalili.github.io/heatmaply/) package to plot an interactive heatmap. Given the dataset's complexity, with numerous countries and variables, interactivity enhances data exploration significantly. Interactive heatmaps allow users to hover over cells to reveal detailed information, offering a richer analysis experience compared to static heatmaps. For more insights and capabilities of **`heatmaply`**, refer to its [documentation](https://cran.r-project.org/web/packages/heatmaply/vignettes/heatmaply.html#is.na10-missing-values).

When crafting a heatmap, some parameters can be varied are:

1.  data transformation method
2.  change of data aggregation level
3.  change of grouped level
4.  change of display

#### Data Preparation

To accommodate diverse inputs such as aggregation method and group-by criteria, we design a function that dynamically processes the dataset based on user-defined parameters. This approach allows for flexibility in analyzing the data without resorting to hard coding.

The code chunk below takes in the dataframe, aggregation method, and group by method, the later 2 are dynamic input computed by the users. The code first prepares a list to accommodate five distinct aggregation methods. Subsequently, it groups the data based on the user-defined categorization, computing aggregated values for various economic indicators while excluding any null entries. The process yields an aggregated dataframe, which is then ready to serve as the basis for heatmap visualization.

```{r}
#| code-fold: false

aggregate_data <- function(data, agg_method, group_level) {
  
  agg_funcs <- list(
    mean = mean,
    max = max,
    min = min,
    median = median,
    var = var
  )
  
  aggregated_data <- data %>%
    group_by(.data[[group_level]]) %>%
    summarise(
      bmi_localprice = agg_funcs[[agg_method]](bmi_localprice, na.rm = TRUE),
      bmi_usd_price = agg_funcs[[agg_method]](bmi_usd_price, na.rm = TRUE),
      bmi_change = agg_funcs[[agg_method]](bmi_change, na.rm = TRUE),
      export_usd = agg_funcs[[agg_method]](export_usd, na.rm = TRUE),
      import_usd = agg_funcs[[agg_method]](import_usd, na.rm = TRUE),
      net_export = agg_funcs[[agg_method]](net_export, na.rm = TRUE),
      GDP = agg_funcs[[agg_method]](GDP, na.rm = TRUE),
      gdp_per_capita = agg_funcs[[agg_method]](gdp_per_capita, na.rm = TRUE),
      inflation = agg_funcs[[agg_method]](inflation, na.rm = TRUE),
      unemployment = agg_funcs[[agg_method]](unemployment, na.rm = TRUE),
      hdi = agg_funcs[[agg_method]](hdi, na.rm = TRUE),
      population = agg_funcs[[agg_method]](population, na.rm = TRUE)
    )
  
  return(aggregated_data)
}
```

#### Data Transformation Method

The package provides three distinct data transformation methods: normalize, scale, and percentile. These transformations are crucial, particularly in the context of our dataset, which spans a wide range of values across various economic indicators. Such disparity in data ranges can obfuscate direct comparisons. Employing these transformation methods enables a more coherent analysis, facilitating clearer comparisons by adjusting the data to a common scale. This is particularly beneficial when analyzing economic indicators, where differences in magnitude can significantly impact the interpretability of the data.

The code below created an aggregated dataframe with mean, grouped by different country and convert it into a matrix for ploting a heatmap with country as the unique indicator per row.

```{r}
#| code-fold: false
# create an aggregated dataframe
bmi_heatmap <- aggregate_data(bmi, "mean", "country")

# convert to a matrix
row.names(bmi_heatmap) <- bmi_heatmap$country
bmi_heatmap_matrix <- data.matrix(bmi_heatmap)
```

::: panel-tabset
## Scale - Column

```{r}
#| code-fold: false
heatmaply(bmi_heatmap_matrix,
          scale = "col")
```

## Scale - Row

```{r}
#| code-fold: false
heatmaply(bmi_heatmap_matrix,
          scale = "row")
```

## Normalize

```{r}
#| code-fold: false
heatmaply(normalize(bmi_heatmap_matrix))
```

## Percentile

```{r}
#| code-fold: false
heatmaply(percentize(bmi_heatmap_matrix))
```
:::

::: callout-important
## Insights on Argument Exposure

The experiments indicate that since the dataset ranges vary significantly (e.g., HDI is small a score while population figures are large), the percentile method emerges as the default choice for its ability to bin countries effectively.

The normalization and column scaling methods also provide insights by highlighting outliers and patterns, making them valuable options.

However, scaling by rows (countries) is less insightful due to its categorical nature and does not facilitate meaningful comparison across different indicators. Thus, all aggregation types should be made available for user exploration.

This inclusivity ensures a broader analytical scope, allowing users to discover outliers with scaling, uncover specific patterns through normalization, and categorize data effectively using the percentile approach.
:::

::: callout-tip
## Analysis Insights

Based on the percentile graph analysis, the local Big Mac price, especially in relation to changes grouped with inflation and population, suggests a potential association among these factors. This observation leads us to infer that the local price of a Big Mac could be closely linked with such factors. For the Big Mac price in USD, it is observed to group with the Human Development Index (HDI) and GDP per capita, indicating that, globally, it may be associated with such economic indicators.

An intriguing aspect of this analysis is the potential connection between the Big Mac price in USD with unemployment, and the change in Big Mac price with population.

To fully comprehend these associations, confirmatory data analysis (CDA) should be conducted. This deeper investigation will help in understanding the underlying patterns and relationships between the price of Big Macs and various economic indicators across different regions.
:::

#### Change of Aggregation Level

Employing different aggregation methods enriches the comparative analysis by highlighting various aspects of the economic indicators across countries. Specifically:

-   **Mean and Median**: These measures provide insights into the central tendency of the economic indicators, offering a snapshot of the typical or average values.

-   **Min and Max**: By showcasing the extremes, these aggregations reveal the full range of the data, from the lowest to the highest values.

-   **Variance**: This measure elucidates the variability or stability of each indicator within a country, indicating how dispersed the values are around the mean.

Each of these aggregation levels serves a distinct purpose in the analysis, allowing for a multifaceted understanding of the data. To explore these different perspectives, user should be able to simply adjust the aggregation method parameter in the function that prepares the data for heatmap visualization.

The code below compare with different aggregation method by changing the input into the function creating the heatmap matrix: `bmi_heatmap <- aggregate_data(bmi, "mean", "country")`

::: panel-tabset
## Mean

the code chunk below plot a heatmap aggregated at mean level

```{r}
#| code-fold: false
# create an aggregated dataframe
bmi_heatmap <- aggregate_data(bmi, "mean", "country")
# convert to a matrix
row.names(bmi_heatmap) <- bmi_heatmap$country
bmi_heatmap_matrix <- data.matrix(bmi_heatmap)
# plot the heatmap
heatmaply(percentize(bmi_heatmap_matrix))
```

## Median

the code chunk below plot a heatmap aggregated at median level

```{r}
#| code-fold: false
# create an aggregated dataframe
bmi_heatmap <- aggregate_data(bmi, "median", "country")
# convert to a matrix
row.names(bmi_heatmap) <- bmi_heatmap$country
bmi_heatmap_matrix <- data.matrix(bmi_heatmap)
# plot the heatmap
heatmaply(percentize(bmi_heatmap_matrix))
```

## Max

the code chunk below plot a heatmap aggregated at max level

```{r}
#| code-fold: false
# create an aggregated dataframe
bmi_heatmap <- aggregate_data(bmi, "max", "country")
# convert to a matrix
row.names(bmi_heatmap) <- bmi_heatmap$country
bmi_heatmap_matrix <- data.matrix(bmi_heatmap)
# plot the heatmap
heatmaply(percentize(bmi_heatmap_matrix))
```

## Min

the code chunk below plot a heatmap aggregated at min level

```{r}
#| code-fold: false
# create an aggregated dataframe
bmi_heatmap <- aggregate_data(bmi, "min", "country")

# convert to a matrix
row.names(bmi_heatmap) <- bmi_heatmap$country
bmi_heatmap_matrix <- data.matrix(bmi_heatmap)

# plot the heatmap
heatmaply(percentize(bmi_heatmap_matrix))
```

## Variance

the code chunk below plot a heatmap aggregated at variance level

```{r}
#| code-fold: false
# create an aggregated dataframe
bmi_heatmap <- aggregate_data(bmi, "var", "country")
# convert to a matrix
row.names(bmi_heatmap) <- bmi_heatmap$country
bmi_heatmap_matrix <- data.matrix(bmi_heatmap)
# plot the heatmap
heatmaply(percentize(bmi_heatmap_matrix))
```
:::

::: callout-important
## **Insights on Argument Exposure**

Exposing all aggregation methods offers valuable insights, particularly at the country level. It enables the discovery of specific patterns across different countries. For example, analyzing variance across indicators can illuminate the stability or volatility of each factor within nations, providing a deeper understanding of economic dynamics. Thus making all aggregation types—mean, median, max, min, and variance—available for exploration, users are empowered to conduct a thorough examination of the dataset from various angles. This flexibility facilitates a more nuanced analysis, allowing users to identify unique trends, outliers, and correlations that might not be apparent under a single aggregation approach.

Setting the mean as the default aggregation method, given its widespread acceptance as a fundamental measure of central tendency. It offers a solid starting point for initial explorations, from which users can then delve deeper into more specific or sophisticated analyses.
:::

#### Change of Grouped Level

The data supports two primary grouping levels: by country and by year, enabling cross-national or temporal comparisons. This versatility allows for nuanced comparisons across different nations or over time.

Similarly like aggregation methods, changing the **`group_level`** parameter in the function alters the heatmap visualization instead of hard coding it.

The code below compare with different group by method by changing the input into the function creating the heatmap matrix: `bmi_heatmap <- aggregate_data(bmi, "mean", "country")`. By experimenting with various scaling methods and grouping by year, we've assessed both mean and variance to elucidate the overarching trends of the variables over time and across countries. Only the best results are shown below.

::: panel-tabset
## year - mean

```{r}
#| code-fold: false
# create an aggregated dataframe
bmi_heatmap <- aggregate_data(bmi, "mean", 'year')
# convert to a matrix
row.names(bmi_heatmap) <- bmi_heatmap$year
bmi_heatmap_matrix <- data.matrix(bmi_heatmap)
# plot the heatmap
heatmaply(percentize(bmi_heatmap_matrix))
```

## year - variance

```{r}
#| code-fold: false
# create an aggregated dataframe
bmi_heatmap <- aggregate_data(bmi, "var", 'year')
# convert to a matrix
row.names(bmi_heatmap) <- bmi_heatmap$year
bmi_heatmap_matrix <- data.matrix(bmi_heatmap)
# plot the heatmap
heatmaply(normalize(bmi_heatmap_matrix))
```

## country

```{r}
#| code-fold: false
# create an aggregated dataframe
bmi_heatmap <- aggregate_data(bmi, "mean", 'country')
# convert to a matrix
row.names(bmi_heatmap) <- bmi_heatmap$country
bmi_heatmap_matrix <- data.matrix(bmi_heatmap)
# plot the heatmap
heatmaply(percentize(bmi_heatmap_matrix))
```
:::

::: callout-important
## Insights **on Argument Exposure**

The analysis framework enables exploration through two pivotal lenses: country and year. Grouping data by country provides a comprehensive, nation-wide analysis, while grouping by year illuminates outliers and temporal dynamics across nations. This dual perspective enriches our understanding of the interplay among various variables, facilitating exploratory data analysis (EDA) that empowers users to uncover and interpret patterns related to these variables. Given its broader applicability, grouping by country will be the default setting, acknowledging its prevalence in analytical explorations.
:::

::: callout-tip
## Analysis Insights

A particularly intriguing finding emerges from the year-by-year analysis, where we observe a mostly chronological arrangement of data points, reflecting national development and expected improvements in various indices over time. However, specific years stand out as outliers, notably 2009, 2010, and 2020. These years correspond to significant global events—the economic crisis of 2009 and the COVID-19 pandemic in 2020—highlighting their impact on the data.

Variance analysis across years shows which factors are most unstable across countries. For example, BMI variability was highest in 2011, inflation in 2019, and other factors varied greatly in 2021, demonstrating the value of this analysis for understanding fluctuations.

Additionally, BMI, net export and import are grouped based on dendrogram, leading to further investigation. This finding prompts us to explore how, beyond typical economic indicators, import and export values might specifically influence Big Mac prices through network analysis.
:::

#### Change of Display

Additional layout method allows the user to on or off the dendrogram by setting dendrogram augement between TRUE and FALSE

```{r}
# create an aggregated dataframe
bmi_heatmap <- aggregate_data(bmi, "mean", 'country')

# convert to a matrix
row.names(bmi_heatmap) <- bmi_heatmap$country
bmi_heatmap_matrix <- data.matrix(bmi_heatmap)
```

::: panel-tabset
## with dendrogram

```{r}
#| code-fold: false

# plot the heatmap
heatmaply(percentize(bmi_heatmap_matrix), 
          dendrogram = TRUE)
```

## without dendrogram

```{r}
#| code-fold: false
# plot the heatmap
heatmaply(percentize(bmi_heatmap_matrix), 
          dendrogram = FALSE)
```
:::

::: callout-important
## Insights **on Argument Exposure**

Given that the dendrogram assists in the initial clustering of countries and variables, offering a hierarchical view of the data, it is recommended to be enabled by default for enhanced analytical depth. This feature enriches the user's ability to discern patterns and relationships within the data, facilitating a more intuitive understanding of complex datasets.
:::

#### Summary

Based on the above experiment, the plot should allow for the functions below to provide enough flexibility for user to conduct statistical exploratory data analysis (EDA) to have a general idea on overall value range and discern potential relationships among variables. With this preliminary EDA, users can subsequently delve into comparative data analysis (CDA) targeting specific variables to test hypotheses.

Key Features for Comprehensive Analysis:

-   **Grouping Method**: Options include by year or country, facilitating targeted analysis.

-   **Aggregation Level**: Supports mean, median, max, min, and variance to accommodate different analytical needs.

-   **Transformation Setting**: Allows scaling, normalization, or percentile-based adjustments for data preparation.

-   **Aesthetic Setting**: Offers the ability to toggle the dendrogram on or off, enhancing visual clarity.

These features ensure that users have the necessary tools to perform robust statistical analysis, laying the groundwork for more complex investigations.

For seamless backend integration, the API setup includes functionalities that cater to diverse analytical preferences below

::: callout-caution
## Summary - API set up

Modifying Input Dataframe: aggregate_data(data, aggregation_by, group_by)

-   group_by: year(default), country

-   aggregation_by: mean(default), median, max, min, var

Modifying heatmaply() for transfomation:

-   scale: heatmaply(data, scale = "col")

-   percentile(default): heatmaply(percentize(data))

-   normalize: heatmaply(normalize(data))

Modifying augement in heatmaply():

-   dendrogram: TRUE(default), FALSE
:::

### **CDA - ASSOCIATION**

After analyzing the heatmap, association tests can be employed to validate hypotheses generated from the heatmap observations, particularly to explore if there's a relationship between any variable and the target Big Mac index, whether in local currency or USD.

The choice of association tests stems from our exploratory data analysis (EDA), where many variables are presented in percentiles or bins due to the significant variance in their ranges. Binning variables can offer additional insights, making the association test particularly suited for our analysis.

The **`ggstatsplot`** package is selected for plotting and conducting association tests because of its versatility, offering a broad array of statistical test options, and its capacity for fine-tuning the analysis. This package supports a wide variety of statistical methods and aesthetic adjustments, making it an excellent tool for our purposes. Documentation is available at [ggstatsplot documentation](https://indrajeetpatil.github.io/ggstatsplot/reference/ggbarstats.html).

Key parameters to consider when conducting comparative data analysis (CDA) include:

-   **Input-related parameters**: Variables for comparison, binning methods, and bin size.

-   **Testing-related parameters**: Type of statistical test and confidence level.

-   **Aesthetic choices**: Representation in percentages or counts.

These considerations ensure a comprehensive and nuanced analysis, allowing for the validation of initial hypotheses and the exploration of deeper associations between variables and the Big Mac index.

#### Data Preparation

To accommodate diverse inputs of binning method and binning size, we design a function that dynamically processes the dataset based on user-defined parameters. This approach allows for flexibility in analyzing the data without resorting to hard coding.

The code chunk below creates 2 functions accepts a dataframe, two column names for binning, the number of bins. It applies either percentile-based binning or equal-sized binning.

```{r}
#| code-fold: false
prepare_binned_data <- function(data, col1, col2, n_bins, method = "percentile") {
  if (method == "percentile") {
    # Binning based on percentiles
    col1_bins <- ntile(data[[col1]], n_bins)
    col2_bins <- ntile(data[[col2]], n_bins)
  } else if (method == "equal") {
    # Binning into equal-sized bins
    col1_bins <- cut(data[[col1]], breaks = n_bins, labels = FALSE)
    col2_bins <- cut(data[[col2]], breaks = n_bins, labels = FALSE)
  } else {
    stop("Invalid binning method specified. Use 'percentile' or 'equal'.")
  }
  
  # Dynamically generate labels based on the actual number of unique bins
  unique_bins_col1 <- length(unique(col1_bins))
  unique_bins_col2 <- length(unique(col2_bins))
  
  data[[col1]] <- factor(col1_bins, levels = 1:unique_bins_col1, labels = paste("Bin", 1:unique_bins_col1))
  data[[col2]] <- factor(col2_bins, levels = 1:unique_bins_col2, labels = paste("Bin", 1:unique_bins_col2))
  
  return(data)
}
```

#### Choice of Variables

::: panel-tabset
## Using bmi_usd_price

```{r}
#| fig-width: 10
#| fig-height: 6
prepared_data <- prepare_binned_data(bmi, "bmi_usd_price", "gdp_per_capita", 5, method = "percentile")

ggbarstats(
  data = prepared_data,
  x = "gdp_per_capita",
  y = "bmi_usd_price",
)
```

## Using bmi_change

```{r}
#| fig-width: 10
#| fig-height: 6

prepared_data <- prepare_binned_data(bmi, "bmi_change", "inflation", 5, method = "percentile")

ggbarstats(
  data = prepared_data,
  y = "bmi_change",
  x = "inflation"
)
```
:::

::: callout-important
## Insights on Argument Exposure

The experiment delves into the dynamics between the Big Mac Index and various factors, positioning Big Mac-related indices prominently for comparative analysis. Among the three Big Mac indices—bmi_usd_dollars, bmi_change, and bmi_localprice—the choice of index for the x-axis is crucial for clarity and insight.

-   **bmi_usd_dollars** serves as a pivotal metric for cross-country comparisons based on pricing, offering a standard scale to assess value discrepancies globally.

-   **bmi_change** provides insights into the temporal price evolution of the Big Mac, revealing trends and fluctuations over time.

-   **bmi_localprice**, while indicative of the Big Mac's price in local currencies, introduces a layer of complexity due to varying currency strengths across countries. This variance may not directly contribute to the analytical objectives, potentially introducing bias rather than clarity.

Therefore, for x-axis variables, **bmi_usd_dollars** and **bmi_change** should be exposed to comapre against all other indicators to uncover significant relationships without the distortion of currency variability.
:::

#### Choice of Binning

::: panel-tabset
## Percentile

```{r}
prepared_data <- prepare_binned_data(bmi, "bmi_change", "inflation", 5, method = "percentile")

ggbarstats(
  data = prepared_data,
  y = "bmi_change",
  x = "inflation"
)

```

## Equal

```{r}
prepared_data <- prepare_binned_data(bmi, "bmi_change", "inflation", 5, method = "equal")

ggbarstats(
  data = prepared_data,
  y = "bmi_change",
  x = "inflation"
)
```
:::

::: callout-important
## Insights on Argument Exposure

Percentile binning is preferred for its ability to evenly distribute observations across bins, especially when variables exhibit large value ranges. Equal binning, focusing more on uniform value intervals, might unduly highlight outliers or specific cases, thereby skewing the analysis. Both options should be provided for analysis.
:::

#### Number of Bins

::: panel-tabset
## Bin = 2

```{r}
prepared_data <- prepare_binned_data(bmi, "bmi_change", "inflation", 2, method = "percentile")

ggbarstats(
  data = prepared_data,
  y = "bmi_change",
  x = "inflation"
)

```

## Bin = 4

```{r}
prepared_data <- prepare_binned_data(bmi, "bmi_change", "inflation", 4, method = "percentile")

ggbarstats(
  data = prepared_data,
  y = "bmi_change",
  x = "inflation"
)
```

## Bin = 7

```{r}
prepared_data <- prepare_binned_data(bmi, "bmi_change", "inflation", 7, method = "percentile")

ggbarstats(
  data = prepared_data,
  y = "bmi_change",
  x = "inflation"
)
```
:::

::: callout-important
## Insights on Argument Exposure

Choosing the right number of bins is crucial: too few (e.g., 2) obscure patterns, while too many (e.g., 7) clutter the plot, hindering analysis. An optimal range of 3-6 bins, with a default of 4, strikes a balance between simplicity and detail, enabling clear and insightful data visualizations.
:::

#### Type of Statistical Test

::: panel-tabset
## parametric

```{r}
prepared_data <- prepare_binned_data(bmi, "bmi_change", "inflation", 4, method = "percentile")

ggbarstats(
  data = prepared_data,
  y = "bmi_change",
  x = "inflation",
  type = "parametric"
)

```

## nonparametric

```{r}
prepared_data <- prepare_binned_data(bmi, "bmi_change", "inflation", 4, method = "percentile")

ggbarstats(
  data = prepared_data,
  y = "bmi_change",
  x = "inflation",
  type = "nonparametric"
)
```

## robust

```{r}
prepared_data <- prepare_binned_data(bmi, "bmi_change", "inflation", 4, method = "percentile")

ggbarstats(
  data = prepared_data,
  y = "bmi_change",
  x = "inflation",
  type = "robust"
)
```

## bayes

```{r}
prepared_data <- prepare_binned_data(bmi, "bmi_change", "inflation", 4, method = "percentile")

ggbarstats(
  data = prepared_data,
  y = "bmi_change",
  x = "inflation",
  type = "bayes"
)
```
:::

::: callout-important
## Insights on Argument Exposure

Parametric, Nonparametric, and robust shows no difference in the display results. Thus only 1 of them and Bayes should be exposed for simplification. Nonparametric tests set as default as it is a reliable alternative when data does not adhere to normal distribution assumptions, ensuring robust analysis across various data types.
:::

#### Choice of Confidence Level

::: panel-tabset
## 95 CI

```{r}
prepared_data <- prepare_binned_data(bmi, "bmi_change", "inflation", 4, method = "percentile")

ggbarstats(
  data = prepared_data,
  y = "bmi_change",
  x = "inflation",
  type = "nonparametric",
  conf.level = 0.95
)

```

## 99 CI

```{r}
prepared_data <- prepare_binned_data(bmi, "bmi_change", "inflation", 4, method = "percentile")

ggbarstats(
  data = prepared_data,
  y = "bmi_change",
  x = "inflation",
  type = "nonparametric",
   conf.level = 0.99
)
```
:::

#### Representation

::: panel-tabset
## percentage

```{r}
prepared_data <- prepare_binned_data(bmi, "bmi_change", "inflation", 4, method = "percentile")

ggbarstats(
  data = prepared_data,
  y = "bmi_change",
  x = "inflation",
  type = "nonparametric",
  conf.level = 0.95,
  label = "percentage"
)

```

## count

```{r}
prepared_data <- prepare_binned_data(bmi, "bmi_change", "inflation", 4, method = "percentile")

ggbarstats(
  data = prepared_data,
  y = "bmi_change",
  x = "inflation",
  type = "nonparametric",
   conf.level = 0.95,
  label = "count"
)
```
:::

#### Summary

Based on the above experiment, the plot should allow for the functions below to provide enough flexibility for user to conduct statistical confirmatory data analysis (EDA) to understand the association between our target variables and other variables.

-   Key Features for Comprehensive Analysis:

-   Choice of Variables: x - BMI related, y - others

-   Binning method: Options include by percentile, or equal

-   Number of Bins: Supports a range of numbers in a slider.

-   Statistical Test: Allows from nonparametric, bayes

-   Confidence Level: 95%, or 99%

-   Aesthetic Setting: Offers the ability to choose label by count of percentage

These features ensure that users have the necessary tools to perform robust statistical analysis, laying the groundwork for more complex investigations.

For seamless backend integration, the API setup includes functionalities that cater to diverse analytical preferences below

::: callout-caution
## Summary - API set up

Modifying Input Dataframe: prepare_binned_data(data, col1, col2, bins, method)

-   col1: bmi-related

-   col2: others

-   bins: integers from 3 to 6

-   method: percentile, equal

Modifying augement in ggbarstats():

-   type: "nonparametric", "bayes"

-   conf.level: 0.95, 0.99

-   label: "count", "percentage"
:::

### UI Design

![](/image/00%20design%20consideration.png)

The overall layout consists of the top navigation bar, which allows navigation among big analysis topics, side navigation filter to navigate between sub analysis. There are 2 plot augment filtering panales, one located at the side, which allows the user to adjust the input related variables, such as x, y, analysis details, group by methods. The one in the main panel allows the user to adjust the individual plot, such as coloring coding, on/off certain features. Below the plotting area, is the text selction, whereby analysis would be displaying at the bottom.

There are 3 special features of this dashboard

1.  the note taking panel allows the user to quickly drop any insights during EDA, and when he change over to the CDA page, he can still refer to the note takings to conduct any test

2.  the insights panel summarized the insights for the analysis as a reference

3.  quick access to the homepage by clicking the icon.

#### Heatmap Page

![](/image/01heatmap.png)

for each individual exposed feature, please refer to the summary above. Instead of using the original argument name, the augment has been renamed and grouped accordingly to unsure better understanding with people who are not familiar with coding.

#### Association Page

![](/image/02association.png)for each individual exposed feature, please refer to the summary above. Instead of using the original argument name, the augment has been renamed and grouped accordingly to unsure better understanding with people who are not familiar with coding.

## **TREE MAP + ANOVA TEST**

### **TREE MAP**

There are 3 methods taught in this class to plot a treemap, using treemap() of treemap package to plot a static treemap, using treemapify package to plot, or d3treeR for an interactive plot. since the data will be already grouped based on its regional groups, there is not much information on the display, an interactive map is not necessary. among the 2 static package, treemap is chosen due to its flexibility and simplicity. the complete documentation could be found [here](https://www.rdocumentation.org/packages/treemap/versions/2.4-4/topics/treemap).

When crafting a treemap, some parameters can be varied are:

-   change of data aggregation level
-   change of grouped level
-   change of variables for display
-   change of algorithm(allow sorting), and color coding

#### Data Preperation

Similarly like the heatmap, an aggregated dataframe should be used and prepared before the plotting

```{r}
#| code-fold: false
aggregate_data <- function(data, agg_method, group_levels) {
  agg_funcs <- list(
    mean = mean,
    max = max,
    min = min,
    median = median,
    var = var
  )
  
  # Ensuring group_levels is a character vector
  if(is.character(group_levels)) {
    group_levels <- syms(group_levels)
  } else {
    stop("group_levels should be a vector of column names.")
  }
  
  aggregated_data <- data %>%
    group_by(!!!group_levels) %>%
    summarise(
      bmi_localprice = agg_funcs[[agg_method]](bmi_localprice, na.rm = TRUE),
      bmi_usd_price = agg_funcs[[agg_method]](bmi_usd_price, na.rm = TRUE),
      bmi_change = agg_funcs[[agg_method]](bmi_change, na.rm = TRUE),
      export_usd = agg_funcs[[agg_method]](export_usd, na.rm = TRUE),
      import_usd = agg_funcs[[agg_method]](import_usd, na.rm = TRUE),
      net_export = agg_funcs[[agg_method]](net_export, na.rm = TRUE),
      GDP = agg_funcs[[agg_method]](GDP, na.rm = TRUE),
      gdp_per_capita = agg_funcs[[agg_method]](gdp_per_capita, na.rm = TRUE),
      inflation = agg_funcs[[agg_method]](inflation, na.rm = TRUE),
      unemployment = agg_funcs[[agg_method]](unemployment, na.rm = TRUE),
      hdi = agg_funcs[[agg_method]](hdi, na.rm = TRUE),
      population = agg_funcs[[agg_method]](population, na.rm = TRUE),
      .groups = 'drop'
    )
  
  return(aggregated_data)
}

```

#### change of data aggregation level

::: panel-tabset
## mean

```{r}
bmi_heatmap <- aggregate_data(bmi_all, "mean", c("continent", "country"))

treemap(bmi_heatmap,
        index = c("continent", "country"),
        vSize = "gdp_per_capita",
        vColor = "bmi_usd_price",
        palette = "RdYlBu",
        type = 'value'
        )
```

## variance

```{r}
bmi_heatmap <- aggregate_data(bmi_all, "var", c("continent", "country"))

treemap(bmi_heatmap,
        index = c("continent", "country"),
        vSize = "gdp_per_capita",
        vColor = "bmi_usd_price",
        palette = "RdYlBu",
        type = 'value'
        )
```

## Max

```{r}
bmi_heatmap <- aggregate_data(bmi_all, "max", c("continent", "country"))

treemap(bmi_heatmap,
        index = c("continent", "country"),
        vSize = "gdp_per_capita",
        vColor = "bmi_usd_price",
        palette = "RdYlBu",
        type = 'value'
        )
```
:::

::: callout-important
## Insights on Argument Exposure

Mean offers a central tendency measure, providing a snapshot of the average outcome across a dataset. It's invaluable for understanding the general behavior of a variable. Variance sheds light on the variability within the dataset, indicating how spread out the data points are from the mean.

While minimum, maximum, and median provide basic data insights, they may not always uncover deeper patterns effectively. Therefore, only mean and variance will be exposed.
:::

#### group by different region group

::: panel-tabset
## continent

```{r}
bmi_heatmap <- aggregate_data(bmi_all, "mean", c("continent", "country"))

treemap(bmi_heatmap,
        index = c("continent", "country"),
        vSize = "gdp_per_capita",
        vColor = "bmi_usd_price",
        palette = "RdYlBu",
        type = 'value'
        )
```

## g20

```{r}
bmi_heatmap <- aggregate_data(bmi_all, "mean", c("g20", "country"))

treemap(bmi_heatmap,
        index = c("g20", "country"),
        vSize = "gdp_per_capita",
        vColor = "bmi_usd_price",
        palette = "RdYlBu",
        type = 'value'
        )
```

## eu

```{r}
bmi_heatmap <- aggregate_data(bmi_all, "mean", c("eu", "country"))

treemap(bmi_heatmap,
        index = c("eu", "country"),
        vSize = "gdp_per_capita",
        vColor = "bmi_usd_price",
        palette = "RdYlBu",
        type = 'value'
        )
```
:::

to visualize with different variables

#### Variables for display

::: panel-tabset
## gdp_per_capita & bmi_usd

```{r}
bmi_heatmap <- aggregate_data(bmi_all, "mean", c("continent", "country"))

treemap(bmi_heatmap,
        index = c("continent", "country"),
        vSize = "gdp_per_capita",
        vColor = "bmi_usd_price",
        palette = "RdYlBu",
        type = 'value'
        )
```

## import_usd & bmi_change

```{r}
bmi_heatmap <- aggregate_data(bmi_all, "mean", c("continent", "country"))

treemap(bmi_heatmap,
        index = c("continent", "country"),
        vSize = "export_usd",
        vColor = "bmi_change",
        palette = "RdYlBu",
        type = 'value'
        )
```

## unemployment & bmi_change

```{r}
bmi_heatmap <- aggregate_data(bmi_all, "mean", c("continent", "country"))

treemap(bmi_heatmap,
        index = c("continent", "country"),
        vSize = "unemployment",
        vColor = "bmi_change",
        palette = "RdYlBu",
        type = 'value'
        )
```
:::

::: callout-tip
## Analysis Insights

The treemap visualization uniquely showcases BMI-related variables alongside others, utilizing spatial grouping or approximation. This method uncovers patterns based on location or organizational insights effectively. For instance, when examining variables like "export_usd" and "bmi_change" by continent, an intriguing pattern emerges: countries in South America tend to display significant changes in their local Big Mac prices. These countries are represented by smaller shapes in the treemap, suggesting lower export trade values. This observation prompts further investigation into two key areas:

1.  the veracity of the apparent higher BMI change in South American countries, and
2.  the potential underlying relationship between export values and BMI changes.
:::

#### Change of Color Coding

::: panel-tabset
## value

```{r}
bmi_heatmap <- aggregate_data(bmi_all, "mean", c("continent", "country"))

treemap(bmi_heatmap,
        index = c("continent", "country"),
        vSize = "gdp_per_capita",
        vColor = "bmi_usd_price",
        palette = "RdYlBu",
        type = 'value'
        )
```

## manual

```{r}
bmi_heatmap <- aggregate_data(bmi_all, "mean", c("continent", "country"))

treemap(bmi_heatmap,
        index = c("continent", "country"),
        vSize = "gdp_per_capita",
        vColor = "bmi_usd_price",
        palette = "RdYlBu",
        type = 'manual'
        )
```
:::

#### Sorting

::: panel-tabset
## without sorting

```{r}
bmi_heatmap <- aggregate_data(bmi_all, "mean", c("continent", "country"))

treemap(bmi_heatmap,
        index = c("continent", "country"),
        vSize = "gdp_per_capita",
        vColor = "bmi_usd_price",
        palette = "RdYlBu",
        type = 'manual'
        )
```

## with sorting

```{r}
bmi_heatmap <- aggregate_data(bmi_all, "mean", c("continent", "country"))

treemap(bmi_heatmap,
        index = c("continent", "country"),
        vSize = "gdp_per_capita",
        vColor = "bmi_usd_price",
        algorithm = "squarified",
        sortID = "bmi_usd_price",
        palette = "RdYlBu",
        type = 'manual'
        )
```
:::

#### Summary

Based on the above experiment, the plot should allow for the functions below to provide enough flexibility for user to conduct statistical exploratory data analysis (EDA) to have a general idea on patterns related to its organizational, or locational characters. With this preliminary EDA, users can subsequently delve into comparative data analysis (CDA) targeting specific variables to test hypotheses.

Key Features for Comprehensive Analysis:

-   **Aggregation Level**: Supports mean, and variance to accommodate different analytical needs.

-   **Grouping Method**: allows at continent(locational), or g20, g7, eu (organizational)

-   **Input Variables**: Allows all variables to be selected as size, and color

-   **Aesthetic Setting**: Offers the ability to select from color coing method, and if sort by its colored variable.

These features ensure that users have the necessary tools to perform robust statistical analysis, laying the groundwork for more complex investigations.

For seamless backend integration, the API setup includes functionalities that cater to diverse analytical preferences below

::: callout-caution
## Summary - API set up

Modifying Input Dataframe: aggregate_data(data, aggregation_by, group_by)

-   group_by: continent(default), g20, g7, eu

-   aggregation_by: mean(default), var

Modifying augement in treemap():

-   vSize

-   vColor

-   type: manual, value

-   algorithm = "squarified", sortID = "col"
:::

### **ANOVA TEST**

Wth this, we can conduct anova test to test on our hypothesis from the EDA above, if any countries, or regions have higher bmi, or other indicators than others. The package used to conduct anova test is the same as the association test, The ggstatsplot package is selected because of its versatility, offering a broad array of statistical test options, and its capacity for fine-tuning the analysis.

Key parameters to consider when conducting comparative data analysis (CDA) include:

-   **Input-related parameters**: compare at the region level or at the individual country level

-   **Testing-related parameters**: Type of statistical test and confidence level.

-   **Aesthetic choices**:Plot type, display type

These considerations ensure a comprehensive and nuanced analysis, allowing for the validation of initial hypotheses and the exploration of deeper associations between variables and the Big Mac index.

#### Level of Details

::: panel-tabset
## by coutry

```{r}
bmi_all_filter <- filter(bmi_all, g7  == TRUE)
ggbetweenstats(
  data = bmi_all_filter,
  x = country, 
  y = bmi_usd_price,
  type = "p",
  mean.ci = TRUE, 
  pairwise.comparisons = TRUE, 
  pairwise.display = "s",
  p.adjust.method = "fdr",
  messages = FALSE
)
```

## by grouped region

```{r}
ggbetweenstats(
  data = bmi_all,
  x = g7, 
  y = bmi_usd_price,
  type = "p",
  mean.ci = TRUE, 
  pairwise.comparisons = TRUE, 
  pairwise.display = "s",
  p.adjust.method = "fdr",
  messages = FALSE
)
```
:::

::: callout-important
## Insights on Argument Exposure

ffering insights across different granularity levels, it's beneficial to provide users with the option to select their desired level of detail. When displaying data at the country level, considerations about data filtering become crucial to avoid overwhelming the visualization and to facilitate meaningful comparisons. Therefore, employing two separate dataframes for plotting—each tailored to a specific granularity level (e.g., country versus region or continent)—ensures that users can navigate through the data effectively, making comparisons and drawing insights in a manner that best suits their analytical needs. This approach enhances the user experience by providing clarity and focus, allowing for a more nuanced exploration of the data.
:::

#### Choice of Statistical test

::: panel-tabset
## parametric

```{r}
bmi_all_filter <- filter(bmi_all, g7  == TRUE)
ggbetweenstats(
  data = bmi_all_filter,
  x = country, 
  y = bmi_usd_price,
  type = "p",
  mean.ci = TRUE, 
  pairwise.comparisons = TRUE, 
  pairwise.display = "s",
  p.adjust.method = "fdr",
  messages = FALSE,
  conf.level = 0.95
)
```

## Non parametric

```{r}
bmi_all_filter <- filter(bmi_all, g7  == TRUE)
ggbetweenstats(
  data = bmi_all_filter,
  x = country, 
  y = bmi_usd_price,
  type = "np",
  mean.ci = TRUE, 
  pairwise.comparisons = TRUE, 
  pairwise.display = "s",
  p.adjust.method = "fdr",
  messages = FALSE,
  conf.level = 0.95
)
```

## robust

```{r}
bmi_all_filter <- filter(bmi_all, g7  == TRUE)
ggbetweenstats(
  data = bmi_all_filter,
  x = country, 
  y = bmi_usd_price,
  type = "r",
  mean.ci = TRUE, 
  pairwise.comparisons = TRUE, 
  pairwise.display = "s",
  p.adjust.method = "fdr",
  messages = FALSE,
  conf.level = 0.95
)
```

## bayes

```{r}
bmi_all_filter <- filter(bmi_all, g7  == TRUE)
ggbetweenstats(
  data = bmi_all_filter,
  x = country, 
  y = bmi_usd_price,
  type = "b",
  mean.ci = TRUE, 
  pairwise.comparisons = TRUE, 
  pairwise.display = "s",
  p.adjust.method = "fdr",
  messages = FALSE,
  conf.level = 0.95
)
```
:::

#### Choice of Confidence Level

::: panel-tabset
## 95 CI

```{r}
bmi_all_filter <- filter(bmi_all, g7  == TRUE)
ggbetweenstats(
  data = bmi_all_filter,
  x = country, 
  y = bmi_usd_price,
  type = "p",
  mean.ci = TRUE, 
  pairwise.comparisons = TRUE, 
  pairwise.display = "s",
  p.adjust.method = "fdr",
  messages = FALSE,
  conf.level = 0.95
)
```

## 99 CI

```{r}
bmi_all_filter <- filter(bmi_all, g7  == TRUE)
ggbetweenstats(
  data = bmi_all_filter,
  x = country, 
  y = bmi_usd_price,
  type = "p",
  mean.ci = TRUE, 
  pairwise.comparisons = TRUE, 
  pairwise.display = "s",
  p.adjust.method = "fdr",
  messages = FALSE,
  conf.level = 0.95
)
```
:::

#### Choice of Display Label

::: panel-tabset
## all

```{r}
bmi_all_filter <- filter(bmi_all, g7  == TRUE)
ggbetweenstats(
  data = bmi_all_filter,
  x = country, 
  y = bmi_usd_price,
  type = "p",
  mean.ci = TRUE, 
  pairwise.comparisons = TRUE, 
  pairwise.display = "all",
  p.adjust.method = "fdr",
  messages = FALSE,
  conf.level = 0.95
)
```

## none

```{r}
bmi_all_filter <- filter(bmi_all, g7  == TRUE)
ggbetweenstats(
  data = bmi_all_filter,
  x = country, 
  y = bmi_usd_price,
  type = "p",
  mean.ci = TRUE, 
  pairwise.comparisons = TRUE, 
  pairwise.display = "none",
  p.adjust.method = "fdr",
  messages = FALSE,
  conf.level = 0.95
)
```

## only significant

```{r}
bmi_all_filter <- filter(bmi_all, g7  == TRUE)
ggbetweenstats(
  data = bmi_all_filter,
  x = country, 
  y = bmi_usd_price,
  type = "p",
  mean.ci = TRUE, 
  pairwise.comparisons = TRUE, 
  pairwise.display = "s",
  p.adjust.method = "fdr",
  messages = FALSE,
  conf.level = 0.95
)
```

## only non-significant

```{r}
bmi_all_filter <- filter(bmi_all, g7  == TRUE)
ggbetweenstats(
  data = bmi_all_filter,
  x = country, 
  y = bmi_usd_price,
  type = "p",
  mean.ci = TRUE, 
  pairwise.comparisons = TRUE, 
  pairwise.display = "ns",
  p.adjust.method = "fdr",
  messages = FALSE,
  conf.level = 0.95
)
```
:::

::: callout-important
## Insights on Argument Exposure

For optimal clarity in data visualization, it's important to focus on displaying only those relationships that are statistically significant, eliminating the need to differentiate between 'all', and 'non-significant', in the analysis. Highlighting significant relationships simplifies the interpretation process, steering attention toward meaningful insights. The inclusion of non-significant data points often adds unnecessary complexity without contributing valuable insights, potentially obscuring the truly impactful findings.
:::

#### Display Plot Type

::: panel-tabset
## both voilin plot and boxpolot

```{r}
bmi_all_filter <- filter(bmi_all, g7  == TRUE)
ggbetweenstats(
  data = bmi_all_filter,
  x = country, 
  y = bmi_usd_price,
  type = "p",
  mean.ci = TRUE, 
  pairwise.comparisons = TRUE, 
  pairwise.display = "all",
  p.adjust.method = "fdr",
  messages = FALSE,
  conf.level = 0.95
)
```

## only voilin plot

```{r}
bmi_all_filter <- filter(bmi_all, g7  == TRUE)
ggbetweenstats(
  data = bmi_all_filter,
  x = country, 
  y = bmi_usd_price,
  type = "p",
  mean.ci = TRUE, 
  pairwise.comparisons = TRUE, 
  pairwise.display = "none",
  p.adjust.method = "fdr",
  messages = FALSE,
  conf.level = 0.95,
  # to remove boxplot
  boxplot.args = list(width = 0)
)
```

## only boxplot

```{r}
bmi_all_filter <- filter(bmi_all, g7  == TRUE)
ggbetweenstats(
  data = bmi_all_filter,
  x = country, 
  y = bmi_usd_price,
  type = "p",
  mean.ci = TRUE, 
  pairwise.comparisons = TRUE, 
  pairwise.display = "s",
  p.adjust.method = "fdr",
  messages = FALSE,
  plot.type = "box",
  conf.level = 0.95,
  # to remove violin plot
  violin.args = list(width = 0, linewidth = 0)
)
```
:::

#### Summary

Based on the above experiment, the plot should allow for the functions below to provide enough flexibility for user to conduct statistical confirmatory data analysis (CDA) via ANOVA test

-   Key Features for Comprehensive Analysis:

-   Level of Details: region, country

-   Statistical Test: Allows from parametric, nonparametric, bayes, robust

-   Confidence Level: 95%, or 99%

-   Aesthetic Setting: Offers the ability to choose display label, and plot type

These features ensure that users have the necessary tools to perform robust statistical analysis, laying the groundwork for more complex investigations.

For seamless backend integration, the API setup includes functionalities that cater to diverse analytical preferences below

::: callout-caution
## Summary - API set up

Modifying Input Dataframe:using bmi data, and filter()

Modifying augement in ggbarstats():

-   type: "parametric", "nonparametric", "bayes", "robust"

-   conf.level: 0.95, 0.99

-   pairwise.display: "all", "none", "none", "s", "ns"

-   off boxplot/violin chart:

    -   boxplot.args = list(width = 0)

    -   violin.args = list(width = 0, linewidth = 0)
:::

#### Tree Map Page

![](/image/03treemap.png)

for each individual exposed feature, please refer to the summary above. Instead of using the original argument name, the augment has been renamed and grouped accordingly to unsure better understanding with people who are not familiar with coding.

#### ANOVA Page

![](/image/04anova.png)

for each individual exposed feature, please refer to the summary above. Instead of using the original argument name, the augment has been renamed and grouped accordingly to unsure better understanding with people who are not familiar with coding.

## **PARAPLOT**

Paraplot offers a way to visualize relationships among multiple variables. Its advantage lies in the comprehensive representation of multidimensional data. The [ggparcoord()](https://ggobi.github.io/ggally/reference/ggparcoord.html) function from the GGally package can be used for creating parallel coordinate plots.

When ploting paraplot, some considerations are:

1.  Select a grouping level such as countries, years, or regions.

2.  Aggregate or facet the data visualization.

3.  Choose a scaling method.

4.  Adjust line opacity.

5.  Toggle boxplots on or off

#### Control Group by Level

::: panel-tabset
## country

```{r}
ggparcoord(data = bmi_all, 
           columns = c(4:15), 
           groupColumn = 1,
           scale = "uniminmax",
           alphaLines = 0.2,
           boxplot = TRUE)
```

## year

```{r}
bmi_all_new <- bmi_all
bmi_all_new$year <- factor(bmi_all_new$year, levels = sort(unique(bmi_all_new$year)))

ggparcoord(data = bmi_all_new, 
           columns = c(4:15), 
           groupColumn = 2,
           scale = "uniminmax",
           alphaLines = 0.2,
           boxplot = TRUE)
```

## continent

```{r}
ggparcoord(data = bmi_all, 
           columns = c(4:15), 
           groupColumn = 16,
           scale = "uniminmax",
           alphaLines = 0.2,
           boxplot = TRUE)
```
:::

::: callout-important
## Insights on Argument Exposure

Paraplot becomes challenging with too many categories, as displaying all countries or years simultaneously can lead to clutter. It's generally more effective for grouped regions, yet even then, the visualization can become overwhelmed by numerous lines.
:::

#### Visualization Level

::: panel-tabset
## Facet

```{r}
ggparcoord(data = bmi_all, 
           groupColumn = 16,
           columns = c(4:15), 
           scale = "uniminmax",
           alphaLines = 0.2,
           boxplot = TRUE) +
  facet_wrap(~ continent) + 
  theme(axis.text.x = element_text(angle = 30))
```

## Aggregated

```{r}
ggparcoord(data = bmi_all, 
           columns = c(4:15), 
           groupColumn = 16,
           scale = "uniminmax",
           alphaLines = 0.2,
           boxplot = TRUE) + 
  theme(axis.text.x = element_text(angle = 30))
```
:::

#### Summary

Paraplot, while useful for certain analyses, may not be the most effective method in contexts where clarity and insightfulness are paramount. Alternatives like treemaps provide intuitive visualization for comparing variables across groups, and statistical methods like ANOVA tests offer rigorous analysis. Additionally, correlation plots can elucidate the relationships among factors. In this case, the paraplot's potential for clutter and redundancy suggests exploring other analytical tools might yield more actionable insights.

## **CORRELATION** + **SCATTER PLOT**

### **CORRELATION**

For the correlation analysis, there are 2 packages covered in this course

-   [**corrplot package**](https://cran.r-project.org/web/packages/corrplot/vignettes/corrplot-intro.html): Tailored for crafting visually appealing correlation matrices. It shines with its vast array of customization options, including varied display shapes, matrix reordering, and distinct customizations for the matrix's upper and lower parts. Importantly, it facilitates using different statistical methods for correlation computation, enhancing its utility for exploratory analysis.

-   [**ggcorrmat() from ggstatsplot**](https://indrajeetpatil.github.io/ggstatsplot/): Integrates well within the ggplot2 ecosystem, offering a structured approach to generating correlation matrices embellished with ggplot2's styling and theming capabilities.

Corrplot package is chosen due to its more aesthetic appealing and offers more custimization options where plotting

When crafting a correlation plot, some parameters can be varied are:

1.  Choice of Correlation Coefficient

2.  Data Filtering Capabilities

3.  Display Customization

#### Data Preperation

All variables used in the correlation analysis must be numerical. The code below select numerical and country column.

```{r}
bmi_numeric <- bmi %>%
  select(country, where(is.numeric))
```

#### Choice of Correlation Coefficient

Users can select the type of statistical correlation coefficient for their analysis, such as Pearson, Spearman, or Kendall. This selection allows for the adaptation of the analysis to the nature of the data and the specific relationships of interest.

Three types of correlation coefficients can be specified using the **`method`** argument in the **`cor()`** function:

-   **Pearson:** The default method, suitable for linear relationships, calculating the linear dependence between variables.

-   **Kendall:** A non-parametric test that measures the ordinal association between variables.

-   **Spearman:** A non-parametric test that assesses how well the relationship between two variables can be described using a monotonic function.

::: panel-tabset
## Pearson

The code chunk below demonstrates the use of the Pearson method.

```{r}
bmi.cor <- cor(bmi_numeric[-1],method = "pearson",use = "complete.obs")
corrplot(bmi.cor,
         diag = FALSE,
         tl.col = "black")
```

## Kendall

The code chunk below demonstrates the use of the Kendall method.

```{r}
bmi.cor <- cor(bmi_numeric[-1],method = "kendall", use = "complete.obs")
a <- corrplot(bmi.cor,
         diag = FALSE,
         tl.col = "black")

```

## Spearman

tThe code chunk below demonstrates the use of the Spearman method.

```{r}
bmi.cor <- cor(bmi_numeric[-1],method = "spearman", use = "complete.obs")
corrplot(bmi.cor,
         diag = FALSE,
         tl.col = "black")
```
:::

::: callout-important
## Insights on Argument Exposure

Among these three, Pearson is the most commonly used method for calculating correlation efficiency. It's set as the default input variable, allowing users to switch between different methods.
:::

#### Data Filtering Capabilities

To hone in on relevant insights, users can filter the input data based on specific criteria, such as particular countries, ranges of years, or predefined groups. This targeted analysis helps in isolating the effects and relationships that are most pertinent to the user's research questions.

Additionally, zooming into specific years or countries can provide more focused analysis. To facilitate this:

-   filtering specific years

-   filtering specific countries

Setting selected columns as variables makes adjustments easier. Below, the column and input are set as variables:

```{r}
x_col <- "year"  
x_input <- "2020"  

filtered_data <- bmi_numeric %>%
  filter(.data[[x_col]] == x_input) %>% 
  select(-.data[[x_col]]) 
```

::: panel-tabset
## Filter by Year

```{r}
x_col <- "year"  
x_input <- "2020"  

filtered_data <- bmi_numeric %>%
  filter(.data[[x_col]] == x_input) %>% 
  select(-.data[[x_col]]) 

bmi.cor <- cor(filtered_data[-1],method = "pearson")
corrplot(bmi.cor,
         diag = FALSE,
         tl.col = "black")
```

## Filter By Country

```{r}
x_col <- "country"  
x_input <- "China"  

filtered_data <- bmi_numeric %>%
  filter(.data[[x_col]] == x_input) %>% 
  select(-.data[[x_col]]) 

bmi.cor <- cor(filtered_data[-1],method = "pearson")
corrplot(bmi.cor,
         diag = FALSE,
         tl.col = "black")
```
:::

#### Aggregated and Faceted Analysis

Offering users the capability to conduct comparative analysis across specific years or countries enriches the analytical depth. However, when direct faceting support is lacking within the chosen package, a practical workaround involves generating two distinct plots for the respective comparisons. These plots can then be arranged side by side on the same webpage through frontend design.

#### Customization Represnetation

::: panel-tabset
## Circle

```{r}

bmi.cor <- cor(bmi_numeric[-1],method = "spearman", use = "complete.obs")

corrplot(bmi.cor,
         diag = FALSE,
         tl.col = "black",
         method = 'circle'
         )
```

## Square

```{r}

bmi.cor <- cor(bmi_numeric[-1],method = "spearman", use = "complete.obs")

corrplot(bmi.cor,
         diag = FALSE,
         tl.col = "black",
         method = 'square'
         )
```

## Ellipse

```{r}

bmi.cor <- cor(bmi_numeric[-1],method = "spearman", use = "complete.obs")

corrplot(bmi.cor,
         diag = FALSE,
         tl.col = "black",
         method = 'ellipse'
         )
```

## Number

```{r}

bmi.cor <- cor(bmi_numeric[-1],method = "spearman", use = "complete.obs")

corrplot(bmi.cor,
         diag = FALSE,
         tl.col = "black",
         method = 'number'
         )
```

## Shade

```{r}

bmi.cor <- cor(bmi_numeric[-1],method = "spearman", use = "complete.obs")

corrplot(bmi.cor,
         diag = FALSE,
         tl.col = "black",
         method = 'shade'
         )
```

## Color

```{r}

bmi.cor <- cor(bmi_numeric[-1],method = "spearman", use = "complete.obs")

corrplot(bmi.cor,
         diag = FALSE,
         tl.col = "black",
         method = 'color'
         )
```

## Pie

```{r}

bmi.cor <- cor(bmi_numeric[-1],method = "spearman", use = "complete.obs")

corrplot(bmi.cor,
         diag = FALSE,
         tl.col = "black",
         method = 'pie'
         )
```
:::

::: callout-important
## Insights on Argument Exposure

-   **'Circle' and 'Square'** provide similar visual cues, differing mainly in shape. Since their informational value is essentially the same, opting for one—such as 'Square'—is sufficient for simplicity.

-   **'Ellipse'** enriches the analysis by indicating the directionality of relationships, adding a layer of insight beyond mere correlation strength.

-   **'Number'** directly presents the correlation coefficients, offering precise quantitative insights at a glance.

-   **'Shade' and 'Color'** resemble a heatmap, effectively visualizing the strength of relationships through color gradients. This method is intuitive and visually engaging, making it easy to identify patterns of interest.

-   **'Pie'**, while creative, tends to clutter the visualization, making it challenging to extract meaningful insights.

Given these considerations, the recommended options to make available for user selection are **'Square'**, **'Ellipse'**, and **'Number'**. These choices balance clarity, informational depth, and ease of interpretation, facilitating a comprehensive and accessible analytical experience.
:::

#### Customized Layout for Upper, Lower

::: panel-tabset
## Upper - number, Lower - ellipse

```{r}
#| fig-width: 15
#| fig-height: 15
#| 
bmi.cor <- cor(bmi_numeric[-1],method = "spearman", use = "complete.obs")

corrplot.mixed(bmi.cor,
         tl.col = "black",
         lower = 'ellipse',
         upper = 'number',
         
         )
```

## All Square

```{r}

bmi.cor <- cor(bmi_numeric[-1],method = "spearman", use = "complete.obs")

corrplot(bmi.cor,
         diag = FALSE,
         tl.col = "black",
         method = 'square'
         )
```
:::

::: callout-important
## Insights on Argument Exposure

Utilizing different styles for representing correlation matrices, such as through corrplot.mixed() instead of the standard corrplot(), introduces a notable change in function usage. While these mixed representations can add visual diversity, they also complicate the plotting process and may lengthen processing time. This added complexity, particularly in a dynamic Shiny interface where users can switch representation methods on-the-fly, may not significantly enhance the analytical value. Given this consideration, opting for a uniform plotting approach without mixed representations is advised to maintain simplicity and efficiency. This decision aligns with the goal of providing a streamlined and effective user experience, prioritizing clarity and speed over the marginal benefits of mixed visual styles.
:::

#### Customized Layout

::: panel-tabset
## Only Lower

```{r}

bmi.cor <- cor(bmi_numeric[-1],method = "spearman", use = "complete.obs")

corrplot(bmi.cor,
         diag = FALSE,
         tl.col = "black",
         method = 'square',
         type = 'lower'
         )
```

## Only Upper

```{r}

bmi.cor <- cor(bmi_numeric[-1],method = "spearman", use = "complete.obs")

corrplot(bmi.cor,
         diag = FALSE,
         tl.col = "black",
         method = 'square',
         type = 'upper'
         )
```

## All

```{r}

bmi.cor <- cor(bmi_numeric[-1],method = "spearman", use = "complete.obs")

corrplot(bmi.cor,
         diag = FALSE,
         tl.col = "black",
         method = 'square'
         )
```
:::

#### Customized Layout - diag

::: panel-tabset
## OFF

```{r}

bmi.cor <- cor(bmi_numeric[-1],method = "spearman", use = "complete.obs")

corrplot(bmi.cor,
         tl.col = "black",
         method = 'square',
         diag = FALSE
         )
```

## ON

```{r}

bmi.cor <- cor(bmi_numeric[-1],method = "spearman", use = "complete.obs")

corrplot(bmi.cor,
         tl.col = "black",
         method = 'square',
         diag = TRUE
         )
```
:::

::: callout-important
## Insights on Argument Exposure

In correlation matrices, the diagonal elements, which represent the correlation of variables with themselves, invariably equal 1. This uniformity means these elements do not contribute additional insights into the interrelationships among the variables. Recognizing this, displaying the diagonal is not essential for enhancing the analytical depth of the plots. Consequently, the option to toggle the visibility of the diagonal will not be offered to users; it will be defaulted to 'off' for all plots. This approach simplifies the visualization, directing focus to the more informative aspects of the correlation matrix and streamlining the user experience by eliminating redundant information.
:::

#### Customized Layout - order

::: panel-tabset
## hclust

```{r}
bmi.cor <- cor(bmi_numeric[-1],method = "spearman", use = "complete.obs")

corrplot(bmi.cor,
         tl.col = "black",
         method = 'square',
         diag = FALSE,
         order = 'hclust'
         )
```

## alphabet

```{r}
bmi.cor <- cor(bmi_numeric[-1],method = "spearman", use = "complete.obs")

corrplot(bmi.cor,
         tl.col = "black",
         method = 'square',
         diag = FALSE,
         order = 'alphabet'
         )
```

## AOE

```{r}
bmi.cor <- cor(bmi_numeric[-1],method = "spearman", use = "complete.obs")

corrplot(bmi.cor,
         tl.col = "black",
         method = 'square',
         diag = FALSE,
         order = 'AOE'
         )
```

## FPC

```{r}
bmi.cor <- cor(bmi_numeric[-1],method = "spearman", use = "complete.obs")

corrplot(bmi.cor,
         tl.col = "black",
         method = 'square',
         diag = FALSE,
         order = 'FPC',
         
         )
```
:::

#### Summary

Based on the above experiment, the plot should allow for the functions below to provide enough flexibility for user to conduct EDA

-   Choice of Correlation Coefficient

-   Data Filtering Capabilities

-   Comparative analysis: At the interface

-   Aesthetic Setting: Represnetation type, layoput type, orders

These features ensure that users have the necessary tools to perform robust statistical analysis, laying the groundwork for more complex investigations.

For seamless backend integration, the API setup includes functionalities that cater to diverse analytical preferences below

::: callout-caution
## Summary - API set up

Modifying Input cor.matrix: cor(data,method)

-   method = "kendall", "pearson", "spearman"

Filtering Input daraframe: x_col, x_input

Modifying augement in corrplot():

-   method: 'square', ‘ellipse', 'number'

-   type = 'lower', 'upper'

-   order: 'hclust', 'alphabet', 'AOE', 'FPC'

-   diag: TRUE, FALSE
:::

### SCATTER PLOT

When identifying pairs of variables that exhibit higher correlation, users can delve deeper into Comparative Data Analysis (CDA) to conduct statistical tests. These tests assess the significance of the observed correlations, offering insights into the strength and reliability of the relationships between variables.

The **`ggstatsplot`** package is chosen due to its capabilities of advanced statistical analysis features, and flexibility.

Key parameters to consider when conducting comparative data analysis (CDA) include:

-   Input-related parameters: Variables for comparison

-   Testing-related parameters: Type of statistical test and confidence level.

-   Aesthetic choices: smoothing method

#### Variables Selection

::: panel-tabset
## bmi_usd_price & gdp_per_capita

```{r}
ggscatterstats(
  data = bmi_all,
  x = gdp_per_capita,
  y = bmi_usd_price,
  marginal = FALSE,
  )

```

## bmi_change & inflation

```{r}
ggscatterstats(
  data = bmi_all,
  x = inflation,
  y = bmi_change,
  marginal = FALSE,
  )

```
:::

::: callout-important
## Insights on Argument Exposure

The choice of the variables can just simply be an input into the plotting function, y should be bmi-related variables, and x are the non bmi-related
:::

#### Type of statistical test & Confidence level

Similarly, type of statistical test & Confidence level can be varied with type, and conf.level argument

```{r}
ggscatterstats(
  data = bmi_all,
  x = inflation,
  y = bmi_change,
  marginal = FALSE,
  type = "parametric",
  conf.level = 0.95
  )

```

#### line smoothing

::: panel-tabset
## loess

```{r}
ggscatterstats(
  data = bmi_all,
  x = inflation,
  y = bmi_change,
  marginal = FALSE,
  type = "parametric",
  conf.level = 0.95,
  smooth.line.args = list(linewidth = 1.5, color = "blue", method = "loess", formula = y ~x)
  )

```

## lm

```{r}
ggscatterstats(
  data = bmi_all,
  x = inflation,
  y = bmi_change,
  marginal = FALSE,
  type = "parametric",
  conf.level = 0.95,
  smooth.line.args = list(linewidth = 1.5, color = "blue", method = "lm", formula = y ~x)
  )

```
:::

#### Summary

Based on the above experiment, the plot should allow for the functions below to provide enough flexibility for user to conduct statistical confirmatory data analysis (CDA)

Key Features for Comprehensive Analysis:

-   Level of Details: region, country

-   Statistical Test: Allows from parametric, nonparametric, bayes, robust

-   Confidence Level: 95%, or 99%

-   Aesthetic Setting: Offers the ability to choose display label, and plot type

These features ensure that users have the necessary tools to perform robust statistical analysis, laying the groundwork for more complex investigations.

For seamless backend integration, the API setup includes functionalities that cater to diverse analytical preferences below

::: callout-caution
## Summary - API set up

Modifying Input Dataframe: select input varibles as x, y columns

Modifying augement in ggscatterstats():

-   type: "parametric", "nonparametric", "bayes", "robust"

-   conf.level: 0.95, 0.99

-   smooth.line.args

    -   method: "loess", "lm"
:::

### UI Design

#### Corroplot Page

![](/image/05corroplot.png)

for each individual exposed feature, please refer to the summary above. Instead of using the original argument name, the augment has been renamed and grouped accordingly to unsure better understanding with people who are not familiar with coding.

#### Compare Page

![](/image/06compare.png)

for this page, it is similar to the correlation map, just allows for 2 additional input to define the left and right plots

#### Scatter Plot

![](/image/07scatter.png)

for each individual exposed feature, please refer to the summary above. Instead of using the original argument name, the augment has been renamed and grouped accordingly to unsure better understanding with people who are not familiar with coding.

# Time Series Clustering

Time series clustering is a methodical approach to grouping similar time series data based on certain characteristics, facilitating pattern recognition and predictive analytics.

For time series clustering, the [**dtwclust**](https://cran.r-project.org/web/packages/dtwclust/index.html) package is used, offering various clustering algorithms and tools tailored for time series data.

```{r}
pacman::p_load(dtwclust, dtw, cluster)
```

## Model Calibration

Key considerations for calibrating the time series clustering model include:

1.  **Input Selection**: Identifying which columns or metrics to incorporate into the clustering analysis.

2.  **Clustering Algorithm**: Selecting the appropriate clustering method. Common options include "partitional" (e.g., k-means) and "hierarchical" clustering, each suitable for different analysis scenarios.

3.  **Seed Value**: Setting an initial seed (defaulted to 2024) to ensure reproducibility of results. Users can modify this seed based on their needs.

4.  **Number of Clusters (k)**: Determining the optimal number of clusters to best categorize the data, which can significantly impact the analysis outcome.

### **Data Preparation**

Based on the documentation, the data input should be: a matrix or data frame where each row is a time series, or a list where each element is a time series. Multivariate series should be provided as a list of matrices where time spans the rows and the variables span the columns of each matrix. Since we have multiple variables, we should firstly convert the dataframe.

The code below firstly drops all missing variables, and then convert it into a multi variant time series matrics.

```{r}
#| code-fold: false

# drop missing values
bmi_clean <- bmi %>%
  filter(complete.cases(.))

# 1. Select relevant columns
bmi_filtered <- select(bmi_clean, -currency_code)

# 2. Convert to a wide format, prepare for conversion to list of matrices
bmi_wide <- bmi_filtered %>%
  pivot_longer(cols = -c(country, year), names_to = "variable", values_to = "value") %>%
  pivot_wider(names_from = variable, values_from = value, names_sort = TRUE) %>%
  arrange(country, year)


# Group by country and convert each group to a matrix
list_matrices_per_country <- bmi_wide %>%
  group_by(country) %>%
  group_split() %>%
  lapply(function(df) {
    # Ensure year is not included in the matrix
    df <- select(df, -country, -year)
    as.matrix(df)
  })

```

### **Perform Time Series Clustering**

#### partitional

the code below build a cluster model with k means clustering method
```{r}
clustering_result <- tsclust(list_matrices_per_country, type = "partitional", k = 4, distance = "dtw")
```

assign the country with the predicted cluster
```{r}
cluster_assignments <- clustering_result@cluster

country_names <- bmi_wide$country %>% unique()

if(length(country_names) == length(cluster_assignments)) {
  country_cluster_df <- data.frame(country = country_names, cluster = cluster_assignments)
} else {
  stop("Mismatch between the number of countries and the number of cluster assignments.")
}
```

conduct dimensional reduction 
```{r}
# Assuming list_matrices_per_country is your list of matrices
features <- lapply(list_matrices_per_country, function(matrix) {
  c(
    mean = mean(matrix, na.rm = TRUE),
    sd = sd(matrix, na.rm = TRUE),
    min = min(matrix, na.rm = TRUE),
    max = max(matrix, na.rm = TRUE)
    # Add other features as needed
  )
})

# Convert the list of features to a data frame
feature_df <- do.call(rbind, features)

# Ensure no missing values
feature_df <- na.omit(feature_df)

# Perform PCA
pca_result <- prcomp(feature_df, center = TRUE, scale. = TRUE)

# Extracting the first two principal components
pc1 <- pca_result$x[, "PC1"]
pc2 <- pca_result$x[, "PC2"]

# Assuming country_names is your vector of country names
pca_df <- data.frame(country = country_names, PC1 = pc1, PC2 = pc2)
```


visualize the model performance with a scatter plot
```{r}
visualization_df <- merge(pca_df, country_cluster_df, by = "country")
plot_ly(data = visualization_df, 
             x = ~PC1, y = ~PC2, 
             type = 'scatter', mode = 'markers',
             text = ~country, # Show country name on hover
             hoverinfo = 'text',
             color = ~factor(cluster), colors = RColorBrewer::brewer.pal(8, "Set1"),
             marker = list(size = 10))
```


#### hierarchical

the code below build a cluster model with k means clustering method
```{r}
clustering_result <- tsclust(list_matrices_per_country, type = "hierarchical", k = 4, distance = "dtw")
```

assign the country with the predicted cluster
```{r}
cluster_assignments <- clustering_result@cluster

country_names <- bmi_wide$country %>% unique()

if(length(country_names) == length(cluster_assignments)) {
  country_cluster_df <- data.frame(country = country_names, cluster = cluster_assignments)
} else {
  stop("Mismatch between the number of countries and the number of cluster assignments.")
}
```

compute mean silhouette score to evaluate the model performance 
```{r}
dist_matrix <- dist(list_matrices_per_country, method = "DTW")

cluster_assignments <- clustering_result@cluster

sil_scores <- silhouette(cluster_assignments, dist_matrix)

mean_sil_width <- mean(sil_scores[, "sil_width"])

print(mean_sil_width)
```


#### Summary
During the model training, there are some adjustable parameters:

-   input:

    -   variables used for clustering

    -   timeframe for analysis

-   model calibration:

    -   type of clustering method to use: **`"partitional"`**, **`"hierarchical"`**

    -   k: Number of desired clusters
    
### Clstering Results Visulization

taking the results of k means with cluster 4
```{r}

clustering_result <- tsclust(list_matrices_per_country, type = "partitional", k = 4, distance = "dtw")
cluster_assignments <- clustering_result@cluster

country_names <- bmi_wide$country %>% unique()

if(length(country_names) == length(cluster_assignments)) {
  country_cluster_df <- data.frame(country = country_names, cluster = cluster_assignments)
} else {
  stop("Mismatch between the number of countries and the number of cluster assignments.")
}
```

The code below display the country and cluster in a dataframe. But it may not be intuitive enough. 
```{r}
country_cluster_df
```

PLotting the relationship with a Dendrogram allows a more intuitive visualization in the cluster assignment. 

```{r}
root_node <- data.frame(cluster = unique(country_cluster_df$cluster))

edges_cluster_country <- country_cluster_df %>%
  select(cluster, country) %>%
  rename(from = cluster, to = country)

edges_root_cluster <- data.frame(from = "", to = root_node$cluster)

edge_list <- rbind(edges_root_cluster, edges_cluster_country)

mygraph <- graph_from_data_frame(edge_list)

# Plot
ggraph(mygraph, layout = 'dendrogram', circular = FALSE) + 
  geom_edge_diagonal() +
  geom_node_point(color="#ffcc00", size=3) +
  geom_node_text(aes(label=name), hjust="inward", nudge_y=0.5) +
  theme_void() +
  coord_flip() +
  scale_y_reverse()
```

Additionally, it is important to understand the number of countries in each cluster.
```{r}
cluster_summary <- country_cluster_df %>%
  group_by(cluster) %>%
  summarise(Count = n())

ggplot(cluster_summary, aes(x = cluster, y = Count)) +
  geom_bar(stat = "identity", fill = "#ffcc00", color = "#ffcc00") +
  geom_text(aes(label = Count), vjust = -0.5, color = "black") + 
  theme_minimal() +
  labs(title = "Number of Countries per Cluster",
       x = "Cluster",
       y = "Number of Countries") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```


## Visualization of Clustered Results

To better understand and visualize the clustering results, consider plotting the results based on its clusters.

```{r}

```


## UI
